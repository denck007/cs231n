{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a 3 layer conv net that gets over 65% test accuracy\n",
    "\n",
    "The idea here is to make go over the search space and see what is even possible. So create a bunch of models over the search space and try and over fit the data. This will generate a refined search space to work in. There isn't really a point to keeping these models around as for the first step we are only looking at the training accuracy.\n",
    "\n",
    "* Start by looking at the entire search space for learning rate, regularization strength, number of filters, and number of hidden neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the (preprocessed) CIFAR10 data.\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cs231n.classifiers.cnn_crp_a_soft import *\n",
    "from cs231n.layers import *\n",
    "from cs231n.layer_utils import *\n",
    "\n",
    "\n",
    "#data that is used to test if a model can overfit data. If it cannot overfit, ignore the model\n",
    "num_overfit = 20\n",
    "overfit_data = {\n",
    "  'X_train': data['X_train'][:num_overfit],\n",
    "  'y_train': data['y_train'][:num_overfit],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "# This is the number of total models to make. The\n",
    "num_points = 1000\n",
    "\n",
    "lr_range = [1e-9,1e-3]\n",
    "reg_range = [1e-9,1e-1]\n",
    "#ws_range = [.009, .05]\n",
    "#num_filters_range = [10,65] # is not end inclusive\n",
    "#hidden_dim_range = [50,501]# is not end inclusive\n",
    "\n",
    "lr = np.random.rand(num_points)*(lr_range[1]-lr_range[0])+lr_range[0]\n",
    "reg = np.random.rand(num_points)*(reg_range[1]-reg_range[0])+reg_range[0]\n",
    "#ws = np.random.rand(num_points)*(ws_range[1]-ws_range[0])+ws_range[0]\n",
    "#num_filters = (np.random.rand(num_points)*(num_filters_range[1]-num_filters_range[0])+num_filters_range[0]).astype(np.int)\n",
    "#hidden_dim = (np.random.rand(num_points)*(hidden_dim_range[1]-hidden_dim_range[0])+hidden_dim_range[0]).astype(np.int)\n",
    "\n",
    "\n",
    "# initialize the score recorder\n",
    "training_score = np.zeros(num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 16) loss: 7.149030\n",
      "Completed model 0/1000, 0.0% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 6.972414\n",
      "Completed model 1/1000, 0.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 12.756360\n",
      "Completed model 2/1000, 0.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.220001\n",
      "Completed model 3/1000, 0.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.477999\n",
      "Completed model 4/1000, 0.4% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 10.982320\n",
      "Completed model 5/1000, 0.5% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 3.325512\n",
      "Completed model 6/1000, 0.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.075047\n",
      "Completed model 7/1000, 0.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.235077\n",
      "Completed model 8/1000, 0.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.563817\n",
      "Completed model 9/1000, 0.9% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 8.345544\n",
      "Completed model 10/1000, 1.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.655588\n",
      "Completed model 11/1000, 1.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.919268\n",
      "Completed model 12/1000, 1.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.700738\n",
      "Completed model 13/1000, 1.3% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.068266\n",
      "Completed model 14/1000, 1.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.715231\n",
      "Completed model 15/1000, 1.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 9.685545\n",
      "Completed model 16/1000, 1.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.603936\n",
      "Completed model 17/1000, 1.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.462408\n",
      "Completed model 18/1000, 1.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.169724\n",
      "Completed model 19/1000, 1.9% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.112054\n",
      "Completed model 20/1000, 2.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.316356\n",
      "Completed model 21/1000, 2.1% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 4.457216\n",
      "Completed model 22/1000, 2.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.569579\n",
      "Completed model 23/1000, 2.3% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 13.982668\n",
      "Completed model 24/1000, 2.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.022768\n",
      "Completed model 25/1000, 2.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.804541\n",
      "Completed model 26/1000, 2.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.782434\n",
      "Completed model 27/1000, 2.7% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 12.595346\n",
      "Completed model 28/1000, 2.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 16.171908\n",
      "Completed model 29/1000, 2.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.355300\n",
      "Completed model 30/1000, 3.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.297717\n",
      "Completed model 31/1000, 3.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.379019\n",
      "Completed model 32/1000, 3.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.101442\n",
      "Completed model 33/1000, 3.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.550151\n",
      "Completed model 34/1000, 3.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.164255\n",
      "Completed model 35/1000, 3.5% complete.\t Training Score: 45.0%\n",
      "(Iteration 1 / 16) loss: 13.113206\n",
      "Completed model 36/1000, 3.6% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 15.526996\n",
      "Completed model 37/1000, 3.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 17.819104\n",
      "Completed model 38/1000, 3.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.168348\n",
      "Completed model 39/1000, 3.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.449574\n",
      "Completed model 40/1000, 4.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.270609\n",
      "Completed model 41/1000, 4.1% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 12.560931\n",
      "Completed model 42/1000, 4.2% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.521310\n",
      "Completed model 43/1000, 4.3% complete.\t Training Score: 55.0%\n",
      "(Iteration 1 / 16) loss: 5.048736\n",
      "Completed model 44/1000, 4.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.652413\n",
      "Completed model 45/1000, 4.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.711072\n",
      "Completed model 46/1000, 4.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 17.328527\n",
      "Completed model 47/1000, 4.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.320441\n",
      "Completed model 48/1000, 4.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.029312\n",
      "Completed model 49/1000, 4.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.365157\n",
      "Completed model 50/1000, 5.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.125410\n",
      "Completed model 51/1000, 5.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.992594\n",
      "Completed model 52/1000, 5.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.649574\n",
      "Completed model 53/1000, 5.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.111599\n",
      "Completed model 54/1000, 5.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.908895\n",
      "Completed model 55/1000, 5.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.825463\n",
      "Completed model 56/1000, 5.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.056315\n",
      "Completed model 57/1000, 5.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.175103\n",
      "Completed model 58/1000, 5.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.336721\n",
      "Completed model 59/1000, 5.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.897660\n",
      "Completed model 60/1000, 6.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.574075\n",
      "Completed model 61/1000, 6.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 17.435420\n",
      "Completed model 62/1000, 6.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.653344\n",
      "Completed model 63/1000, 6.3% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.381424\n",
      "Completed model 64/1000, 6.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.450294\n",
      "Completed model 65/1000, 6.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.017588\n",
      "Completed model 66/1000, 6.6% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.557082\n",
      "Completed model 67/1000, 6.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.641129\n",
      "Completed model 68/1000, 6.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.918399\n",
      "Completed model 69/1000, 6.9% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.220632\n",
      "Completed model 70/1000, 7.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.649452\n",
      "Completed model 71/1000, 7.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 14.481401\n",
      "Completed model 72/1000, 7.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.520753\n",
      "Completed model 73/1000, 7.3% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.743263\n",
      "Completed model 74/1000, 7.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.933076\n",
      "Completed model 75/1000, 7.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.186454\n",
      "Completed model 76/1000, 7.6% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 6.098702\n",
      "Completed model 77/1000, 7.7% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 5.937942\n",
      "Completed model 78/1000, 7.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.383225\n",
      "Completed model 79/1000, 7.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.995820\n",
      "Completed model 80/1000, 8.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.946548\n",
      "Completed model 81/1000, 8.1% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 16.125110\n",
      "Completed model 82/1000, 8.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 9.883787\n",
      "Completed model 83/1000, 8.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.549004\n",
      "Completed model 84/1000, 8.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.184175\n",
      "Completed model 85/1000, 8.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.594889\n",
      "Completed model 86/1000, 8.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.561102\n",
      "Completed model 87/1000, 8.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.228806\n",
      "Completed model 88/1000, 8.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.763448\n",
      "Completed model 89/1000, 8.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.840996\n",
      "Completed model 90/1000, 9.0% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 11.652359\n",
      "Completed model 91/1000, 9.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.372871\n",
      "Completed model 92/1000, 9.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 14.929164\n",
      "Completed model 93/1000, 9.3% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 15.494933\n",
      "Completed model 94/1000, 9.4% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 12.039140\n",
      "Completed model 95/1000, 9.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.187139\n",
      "Completed model 96/1000, 9.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.889354\n",
      "Completed model 97/1000, 9.7% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 3.073974\n",
      "Completed model 98/1000, 9.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.378357\n",
      "Completed model 99/1000, 9.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.683863\n",
      "Completed model 100/1000, 10.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.151552\n",
      "Completed model 101/1000, 10.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.324857\n",
      "Completed model 102/1000, 10.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.573584\n",
      "Completed model 103/1000, 10.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.820963\n",
      "Completed model 104/1000, 10.4% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 5.635908\n",
      "Completed model 105/1000, 10.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 3.850732\n",
      "Completed model 106/1000, 10.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.828672\n",
      "Completed model 107/1000, 10.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 19.205326\n",
      "Completed model 108/1000, 10.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.236309\n",
      "Completed model 109/1000, 10.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.814521\n",
      "Completed model 110/1000, 11.0% complete.\t Training Score: 40.0%\n",
      "(Iteration 1 / 16) loss: 7.366243\n",
      "Completed model 111/1000, 11.1% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 13.865963\n",
      "Completed model 112/1000, 11.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 10.441905\n",
      "Completed model 113/1000, 11.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.294832\n",
      "Completed model 114/1000, 11.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 16.364192\n",
      "Completed model 115/1000, 11.5% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 10.480581\n",
      "Completed model 116/1000, 11.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.545258\n",
      "Completed model 117/1000, 11.7% complete.\t Training Score: 40.0%\n",
      "(Iteration 1 / 16) loss: 13.253554\n",
      "Completed model 118/1000, 11.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.894259\n",
      "Completed model 119/1000, 11.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.409992\n",
      "Completed model 120/1000, 12.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.886996\n",
      "Completed model 121/1000, 12.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.836698\n",
      "Completed model 122/1000, 12.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.927268\n",
      "Completed model 123/1000, 12.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.056323\n",
      "Completed model 124/1000, 12.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.312803\n",
      "Completed model 125/1000, 12.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.671639\n",
      "Completed model 126/1000, 12.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.328646\n",
      "Completed model 127/1000, 12.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.176125\n",
      "Completed model 128/1000, 12.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.837607\n",
      "Completed model 129/1000, 12.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.294618\n",
      "Completed model 130/1000, 13.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.820826\n",
      "Completed model 131/1000, 13.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.113974\n",
      "Completed model 132/1000, 13.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.826909\n",
      "Completed model 133/1000, 13.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 3.917703\n",
      "Completed model 134/1000, 13.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.722730\n",
      "Completed model 135/1000, 13.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.649481\n",
      "Completed model 136/1000, 13.6% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 5.928607\n",
      "Completed model 137/1000, 13.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.683120\n",
      "Completed model 138/1000, 13.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.268315\n",
      "Completed model 139/1000, 13.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.701007\n",
      "Completed model 140/1000, 14.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.035916\n",
      "Completed model 141/1000, 14.1% complete.\t Training Score: 15.0%\n",
      "(Iteration 1 / 16) loss: 15.047353\n",
      "Completed model 142/1000, 14.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 6.210153\n",
      "Completed model 143/1000, 14.3% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 6.822541\n",
      "Completed model 144/1000, 14.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.565183\n",
      "Completed model 145/1000, 14.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.279275\n",
      "Completed model 146/1000, 14.6% complete.\t Training Score: 50.0%\n",
      "(Iteration 1 / 16) loss: 6.552835\n",
      "Completed model 147/1000, 14.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.920483\n",
      "Completed model 148/1000, 14.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.491960\n",
      "Completed model 149/1000, 14.9% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 8.522224\n",
      "Completed model 150/1000, 15.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.937430\n",
      "Completed model 151/1000, 15.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.151072\n",
      "Completed model 152/1000, 15.2% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 12.354821\n",
      "Completed model 153/1000, 15.3% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 14.582662\n",
      "Completed model 154/1000, 15.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.842480\n",
      "Completed model 155/1000, 15.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.077732\n",
      "Completed model 156/1000, 15.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.804343\n",
      "Completed model 157/1000, 15.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.872393\n",
      "Completed model 158/1000, 15.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.646677\n",
      "Completed model 159/1000, 15.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 16.271214\n",
      "Completed model 160/1000, 16.0% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 8.288195\n",
      "Completed model 161/1000, 16.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.225208\n",
      "Completed model 162/1000, 16.2% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 5.685892\n",
      "Completed model 163/1000, 16.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.705085\n",
      "Completed model 164/1000, 16.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.031774\n",
      "Completed model 165/1000, 16.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.687646\n",
      "Completed model 166/1000, 16.6% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 12.483929\n",
      "Completed model 167/1000, 16.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.265658\n",
      "Completed model 168/1000, 16.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.676360\n",
      "Completed model 169/1000, 16.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.042064\n",
      "Completed model 170/1000, 17.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 8.199206\n",
      "Completed model 171/1000, 17.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.387180\n",
      "Completed model 172/1000, 17.2% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 16.233094\n",
      "Completed model 173/1000, 17.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.620087\n",
      "Completed model 174/1000, 17.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.898545\n",
      "Completed model 175/1000, 17.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.004613\n",
      "Completed model 176/1000, 17.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.178743\n",
      "Completed model 177/1000, 17.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.833624\n",
      "Completed model 178/1000, 17.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.259054\n",
      "Completed model 179/1000, 17.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.713840\n",
      "Completed model 180/1000, 18.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.968826\n",
      "Completed model 181/1000, 18.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.937276\n",
      "Completed model 182/1000, 18.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.542849\n",
      "Completed model 183/1000, 18.3% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 11.999378\n",
      "Completed model 184/1000, 18.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.767442\n",
      "Completed model 185/1000, 18.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.193280\n",
      "Completed model 186/1000, 18.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.209369\n",
      "Completed model 187/1000, 18.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.862049\n",
      "Completed model 188/1000, 18.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 14.194910\n",
      "Completed model 189/1000, 18.9% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 10.664428\n",
      "Completed model 190/1000, 19.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.889060\n",
      "Completed model 191/1000, 19.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.598132\n",
      "Completed model 192/1000, 19.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 3.380082\n",
      "Completed model 193/1000, 19.3% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 11.388238\n",
      "Completed model 194/1000, 19.4% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 16.029807\n",
      "Completed model 195/1000, 19.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.111920\n",
      "Completed model 196/1000, 19.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.600377\n",
      "Completed model 197/1000, 19.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.143697\n",
      "Completed model 198/1000, 19.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 7.796944\n",
      "Completed model 199/1000, 19.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 3.285235\n",
      "Completed model 200/1000, 20.0% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.630994\n",
      "Completed model 201/1000, 20.1% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 13.644295\n",
      "Completed model 202/1000, 20.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.116408\n",
      "Completed model 203/1000, 20.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 16.600960\n",
      "Completed model 204/1000, 20.4% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 11.660083\n",
      "Completed model 205/1000, 20.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.085710\n",
      "Completed model 206/1000, 20.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.859320\n",
      "Completed model 207/1000, 20.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.397442\n",
      "Completed model 208/1000, 20.8% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 12.415923\n",
      "Completed model 209/1000, 20.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.855399\n",
      "Completed model 210/1000, 21.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.854975\n",
      "Completed model 211/1000, 21.1% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.397970\n",
      "Completed model 212/1000, 21.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.406241\n",
      "Completed model 213/1000, 21.3% complete.\t Training Score: 20.0%\n",
      "(Iteration 1 / 16) loss: 16.246132\n",
      "Completed model 214/1000, 21.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.340081\n",
      "Completed model 215/1000, 21.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.943208\n",
      "Completed model 216/1000, 21.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.444762\n",
      "Completed model 217/1000, 21.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.364812\n",
      "Completed model 218/1000, 21.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.441021\n",
      "Completed model 219/1000, 21.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.650520\n",
      "Completed model 220/1000, 22.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.438767\n",
      "Completed model 221/1000, 22.1% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 14.903954\n",
      "Completed model 222/1000, 22.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 7.236509\n",
      "Completed model 223/1000, 22.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.332561\n",
      "Completed model 224/1000, 22.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.045901\n",
      "Completed model 225/1000, 22.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.846118\n",
      "Completed model 226/1000, 22.6% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 9.878505\n",
      "Completed model 227/1000, 22.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.043481\n",
      "Completed model 228/1000, 22.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.744694\n",
      "Completed model 229/1000, 22.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.721888\n",
      "Completed model 230/1000, 23.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.437953\n",
      "Completed model 231/1000, 23.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.862713\n",
      "Completed model 232/1000, 23.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.730226\n",
      "Completed model 233/1000, 23.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.290691\n",
      "Completed model 234/1000, 23.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.340247\n",
      "Completed model 235/1000, 23.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.728868\n",
      "Completed model 236/1000, 23.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.572064\n",
      "Completed model 237/1000, 23.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.482919\n",
      "Completed model 238/1000, 23.8% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 12.852434\n",
      "Completed model 239/1000, 23.9% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 13.277617\n",
      "Completed model 240/1000, 24.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.115828\n",
      "Completed model 241/1000, 24.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.754590\n",
      "Completed model 242/1000, 24.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.459541\n",
      "Completed model 243/1000, 24.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.087579\n",
      "Completed model 244/1000, 24.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.588799\n",
      "Completed model 245/1000, 24.5% complete.\t Training Score: 55.0%\n",
      "(Iteration 1 / 16) loss: 11.139699\n",
      "Completed model 246/1000, 24.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.900739\n",
      "Completed model 247/1000, 24.7% complete.\t Training Score: 50.0%\n",
      "(Iteration 1 / 16) loss: 14.905550\n",
      "Completed model 248/1000, 24.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.847017\n",
      "Completed model 249/1000, 24.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.004852\n",
      "Completed model 250/1000, 25.0% complete.\t Training Score: 45.0%\n",
      "(Iteration 1 / 16) loss: 6.668426\n",
      "Completed model 251/1000, 25.1% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 12.382342\n",
      "Completed model 252/1000, 25.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.401644\n",
      "Completed model 253/1000, 25.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.226095\n",
      "Completed model 254/1000, 25.4% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 15.277241\n",
      "Completed model 255/1000, 25.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.170276\n",
      "Completed model 256/1000, 25.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.980329\n",
      "Completed model 257/1000, 25.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.013416\n",
      "Completed model 258/1000, 25.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.167988\n",
      "Completed model 259/1000, 25.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.664571\n",
      "Completed model 260/1000, 26.0% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 4.714751\n",
      "Completed model 261/1000, 26.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.063267\n",
      "Completed model 262/1000, 26.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.145677\n",
      "Completed model 263/1000, 26.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.151042\n",
      "Completed model 264/1000, 26.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.725090\n",
      "Completed model 265/1000, 26.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.991748\n",
      "Completed model 266/1000, 26.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.126331\n",
      "Completed model 267/1000, 26.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.962418\n",
      "Completed model 268/1000, 26.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.294941\n",
      "Completed model 269/1000, 26.9% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 8.234946\n",
      "Completed model 270/1000, 27.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.290773\n",
      "Completed model 271/1000, 27.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.150319\n",
      "Completed model 272/1000, 27.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.291478\n",
      "Completed model 273/1000, 27.3% complete.\t Training Score: 20.0%\n",
      "(Iteration 1 / 16) loss: 9.868431\n",
      "Completed model 274/1000, 27.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.574725\n",
      "Completed model 275/1000, 27.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.120028\n",
      "Completed model 276/1000, 27.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.466621\n",
      "Completed model 277/1000, 27.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.650869\n",
      "Completed model 278/1000, 27.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 13.824645\n",
      "Completed model 279/1000, 27.9% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 9.841097\n",
      "Completed model 280/1000, 28.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.146626\n",
      "Completed model 281/1000, 28.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.503277\n",
      "Completed model 282/1000, 28.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 2.873245\n",
      "Completed model 283/1000, 28.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.550925\n",
      "Completed model 284/1000, 28.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.188282\n",
      "Completed model 285/1000, 28.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.920418\n",
      "Completed model 286/1000, 28.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.858847\n",
      "Completed model 287/1000, 28.7% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 11.647125\n",
      "Completed model 288/1000, 28.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.938750\n",
      "Completed model 289/1000, 28.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.292245\n",
      "Completed model 290/1000, 29.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.139434\n",
      "Completed model 291/1000, 29.1% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 10.444415\n",
      "Completed model 292/1000, 29.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 18.845347\n",
      "Completed model 293/1000, 29.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.981229\n",
      "Completed model 294/1000, 29.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.812428\n",
      "Completed model 295/1000, 29.5% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.526600\n",
      "Completed model 296/1000, 29.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.520327\n",
      "Completed model 297/1000, 29.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.355789\n",
      "Completed model 298/1000, 29.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 6.385131\n",
      "Completed model 299/1000, 29.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.360046\n",
      "Completed model 300/1000, 30.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.626178\n",
      "Completed model 301/1000, 30.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.063470\n",
      "Completed model 302/1000, 30.2% complete.\t Training Score: 50.0%\n",
      "(Iteration 1 / 16) loss: 8.476851\n",
      "Completed model 303/1000, 30.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 3.328962\n",
      "Completed model 304/1000, 30.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.181935\n",
      "Completed model 305/1000, 30.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.110325\n",
      "Completed model 306/1000, 30.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.816427\n",
      "Completed model 307/1000, 30.7% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 10.464376\n",
      "Completed model 308/1000, 30.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.611316\n",
      "Completed model 309/1000, 30.9% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 7.999351\n",
      "Completed model 310/1000, 31.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.409239\n",
      "Completed model 311/1000, 31.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.771658\n",
      "Completed model 312/1000, 31.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.450256\n",
      "Completed model 313/1000, 31.3% complete.\t Training Score: 30.0%\n",
      "(Iteration 1 / 16) loss: 13.703339\n",
      "Completed model 314/1000, 31.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.829778\n",
      "Completed model 315/1000, 31.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.057334\n",
      "Completed model 316/1000, 31.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.703341\n",
      "Completed model 317/1000, 31.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.576122\n",
      "Completed model 318/1000, 31.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 8.260905\n",
      "Completed model 319/1000, 31.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.282369\n",
      "Completed model 320/1000, 32.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.294852\n",
      "Completed model 321/1000, 32.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.670607\n",
      "Completed model 322/1000, 32.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.997734\n",
      "Completed model 323/1000, 32.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.172941\n",
      "Completed model 324/1000, 32.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.953686\n",
      "Completed model 325/1000, 32.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 5.945092\n",
      "Completed model 326/1000, 32.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.055945\n",
      "Completed model 327/1000, 32.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.839351\n",
      "Completed model 328/1000, 32.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.358030\n",
      "Completed model 329/1000, 32.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.893698\n",
      "Completed model 330/1000, 33.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.068238\n",
      "Completed model 331/1000, 33.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.840920\n",
      "Completed model 332/1000, 33.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.413145\n",
      "Completed model 333/1000, 33.3% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 5.010292\n",
      "Completed model 334/1000, 33.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.030711\n",
      "Completed model 335/1000, 33.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.278770\n",
      "Completed model 336/1000, 33.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.032182\n",
      "Completed model 337/1000, 33.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 12.141455\n",
      "Completed model 338/1000, 33.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.990563\n",
      "Completed model 339/1000, 33.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.772554\n",
      "Completed model 340/1000, 34.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.823573\n",
      "Completed model 341/1000, 34.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.406467\n",
      "Completed model 342/1000, 34.2% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 8.338837\n",
      "Completed model 343/1000, 34.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.405870\n",
      "Completed model 344/1000, 34.4% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.796222\n",
      "Completed model 345/1000, 34.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.600733\n",
      "Completed model 346/1000, 34.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.071780\n",
      "Completed model 347/1000, 34.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.502643\n",
      "Completed model 348/1000, 34.8% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 12.262082\n",
      "Completed model 349/1000, 34.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.530984\n",
      "Completed model 350/1000, 35.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.645719\n",
      "Completed model 351/1000, 35.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.864957\n",
      "Completed model 352/1000, 35.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.824621\n",
      "Completed model 353/1000, 35.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.823864\n",
      "Completed model 354/1000, 35.4% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 9.673208\n",
      "Completed model 355/1000, 35.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.863142\n",
      "Completed model 356/1000, 35.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.781430\n",
      "Completed model 357/1000, 35.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.808056\n",
      "Completed model 358/1000, 35.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.260758\n",
      "Completed model 359/1000, 35.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.038608\n",
      "Completed model 360/1000, 36.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.923275\n",
      "Completed model 361/1000, 36.1% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 9.629114\n",
      "Completed model 362/1000, 36.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.823346\n",
      "Completed model 363/1000, 36.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.380721\n",
      "Completed model 364/1000, 36.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.258005\n",
      "Completed model 365/1000, 36.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.937228\n",
      "Completed model 366/1000, 36.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.268786\n",
      "Completed model 367/1000, 36.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.965179\n",
      "Completed model 368/1000, 36.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.848627\n",
      "Completed model 369/1000, 36.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.214821\n",
      "Completed model 370/1000, 37.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.840121\n",
      "Completed model 371/1000, 37.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 6.081524\n",
      "Completed model 372/1000, 37.2% complete.\t Training Score: 40.0%\n",
      "(Iteration 1 / 16) loss: 15.479376\n",
      "Completed model 373/1000, 37.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 16.114000\n",
      "Completed model 374/1000, 37.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.522317\n",
      "Completed model 375/1000, 37.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.782974\n",
      "Completed model 376/1000, 37.6% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 8.747594\n",
      "Completed model 377/1000, 37.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.371895\n",
      "Completed model 378/1000, 37.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.343692\n",
      "Completed model 379/1000, 37.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.348551\n",
      "Completed model 380/1000, 38.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.303855\n",
      "Completed model 381/1000, 38.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.469626\n",
      "Completed model 382/1000, 38.2% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 14.234491\n",
      "Completed model 383/1000, 38.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.027871\n",
      "Completed model 384/1000, 38.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.241425\n",
      "Completed model 385/1000, 38.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.513288\n",
      "Completed model 386/1000, 38.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.580665\n",
      "Completed model 387/1000, 38.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.831374\n",
      "Completed model 388/1000, 38.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.996409\n",
      "Completed model 389/1000, 38.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.254830\n",
      "Completed model 390/1000, 39.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.756540\n",
      "Completed model 391/1000, 39.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.384109\n",
      "Completed model 392/1000, 39.2% complete.\t Training Score: 40.0%\n",
      "(Iteration 1 / 16) loss: 9.851557\n",
      "Completed model 393/1000, 39.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.921028\n",
      "Completed model 394/1000, 39.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.022263\n",
      "Completed model 395/1000, 39.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 3.995134\n",
      "Completed model 396/1000, 39.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.417502\n",
      "Completed model 397/1000, 39.7% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 6.991555\n",
      "Completed model 398/1000, 39.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 11.976263\n",
      "Completed model 399/1000, 39.9% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.801524\n",
      "Completed model 400/1000, 40.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.033881\n",
      "Completed model 401/1000, 40.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.647653\n",
      "Completed model 402/1000, 40.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.863861\n",
      "Completed model 403/1000, 40.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.438579\n",
      "Completed model 404/1000, 40.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.820689\n",
      "Completed model 405/1000, 40.5% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 3.882219\n",
      "Completed model 406/1000, 40.6% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 13.517151\n",
      "Completed model 407/1000, 40.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.393340\n",
      "Completed model 408/1000, 40.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 5.237141\n",
      "Completed model 409/1000, 40.9% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 14.777081\n",
      "Completed model 410/1000, 41.0% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 14.476052\n",
      "Completed model 411/1000, 41.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.303952\n",
      "Completed model 412/1000, 41.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.908489\n",
      "Completed model 413/1000, 41.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.689259\n",
      "Completed model 414/1000, 41.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.126470\n",
      "Completed model 415/1000, 41.5% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 14.055839\n",
      "Completed model 416/1000, 41.6% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.564356\n",
      "Completed model 417/1000, 41.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 3.032098\n",
      "Completed model 418/1000, 41.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 11.611770\n",
      "Completed model 419/1000, 41.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.215285\n",
      "Completed model 420/1000, 42.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.111043\n",
      "Completed model 421/1000, 42.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.964115\n",
      "Completed model 422/1000, 42.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.124853\n",
      "Completed model 423/1000, 42.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.135330\n",
      "Completed model 424/1000, 42.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.505947\n",
      "Completed model 425/1000, 42.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.887066\n",
      "Completed model 426/1000, 42.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.569771\n",
      "Completed model 427/1000, 42.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.678186\n",
      "Completed model 428/1000, 42.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.432303\n",
      "Completed model 429/1000, 42.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.232265\n",
      "Completed model 430/1000, 43.0% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 17.124786\n",
      "Completed model 431/1000, 43.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 11.445736\n",
      "Completed model 432/1000, 43.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 7.222182\n",
      "Completed model 433/1000, 43.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.856965\n",
      "Completed model 434/1000, 43.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 16.231969\n",
      "Completed model 435/1000, 43.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.898148\n",
      "Completed model 436/1000, 43.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.632284\n",
      "Completed model 437/1000, 43.7% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 9.656947\n",
      "Completed model 438/1000, 43.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.926317\n",
      "Completed model 439/1000, 43.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.688923\n",
      "Completed model 440/1000, 44.0% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 11.584324\n",
      "Completed model 441/1000, 44.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.377352\n",
      "Completed model 442/1000, 44.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 2.828431\n",
      "Completed model 443/1000, 44.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.713725\n",
      "Completed model 444/1000, 44.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.996836\n",
      "Completed model 445/1000, 44.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.000322\n",
      "Completed model 446/1000, 44.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.904724\n",
      "Completed model 447/1000, 44.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.642113\n",
      "Completed model 448/1000, 44.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.831063\n",
      "Completed model 449/1000, 44.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.937458\n",
      "Completed model 450/1000, 45.0% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 6.396448\n",
      "Completed model 451/1000, 45.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 6.341652\n",
      "Completed model 452/1000, 45.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.708620\n",
      "Completed model 453/1000, 45.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.926216\n",
      "Completed model 454/1000, 45.4% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 3.283170\n",
      "Completed model 455/1000, 45.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.079928\n",
      "Completed model 456/1000, 45.6% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.375169\n",
      "Completed model 457/1000, 45.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.583908\n",
      "Completed model 458/1000, 45.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.770711\n",
      "Completed model 459/1000, 45.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.155962\n",
      "Completed model 460/1000, 46.0% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.674253\n",
      "Completed model 461/1000, 46.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.259843\n",
      "Completed model 462/1000, 46.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.454691\n",
      "Completed model 463/1000, 46.3% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.066631\n",
      "Completed model 464/1000, 46.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.660786\n",
      "Completed model 465/1000, 46.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 17.843152\n",
      "Completed model 466/1000, 46.6% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 4.877751\n",
      "Completed model 467/1000, 46.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 2.273128\n",
      "Completed model 468/1000, 46.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.440546\n",
      "Completed model 469/1000, 46.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.867492\n",
      "Completed model 470/1000, 47.0% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 7.408990\n",
      "Completed model 471/1000, 47.1% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 15.075197\n",
      "Completed model 472/1000, 47.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.260591\n",
      "Completed model 473/1000, 47.3% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 13.861566\n",
      "Completed model 474/1000, 47.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.146103\n",
      "Completed model 475/1000, 47.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.520216\n",
      "Completed model 476/1000, 47.6% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 6.745648\n",
      "Completed model 477/1000, 47.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.671336\n",
      "Completed model 478/1000, 47.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.420656\n",
      "Completed model 479/1000, 47.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.456995\n",
      "Completed model 480/1000, 48.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.942189\n",
      "Completed model 481/1000, 48.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.924558\n",
      "Completed model 482/1000, 48.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.977478\n",
      "Completed model 483/1000, 48.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.543461\n",
      "Completed model 484/1000, 48.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.107048\n",
      "Completed model 485/1000, 48.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.424270\n",
      "Completed model 486/1000, 48.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.161323\n",
      "Completed model 487/1000, 48.7% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 7.202609\n",
      "Completed model 488/1000, 48.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 11.026159\n",
      "Completed model 489/1000, 48.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.123328\n",
      "Completed model 490/1000, 49.0% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 13.243187\n",
      "Completed model 491/1000, 49.1% complete.\t Training Score: 15.0%\n",
      "(Iteration 1 / 16) loss: 15.421975\n",
      "Completed model 492/1000, 49.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 8.854911\n",
      "Completed model 493/1000, 49.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.103775\n",
      "Completed model 494/1000, 49.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.268407\n",
      "Completed model 495/1000, 49.5% complete.\t Training Score: 45.0%\n",
      "(Iteration 1 / 16) loss: 6.885351\n",
      "Completed model 496/1000, 49.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.329036\n",
      "Completed model 497/1000, 49.7% complete.\t Training Score: 50.0%\n",
      "(Iteration 1 / 16) loss: 14.579084\n",
      "Completed model 498/1000, 49.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.014913\n",
      "Completed model 499/1000, 49.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.090440\n",
      "Completed model 500/1000, 50.0% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 16.994311\n",
      "Completed model 501/1000, 50.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.291451\n",
      "Completed model 502/1000, 50.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.464239\n",
      "Completed model 503/1000, 50.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.946298\n",
      "Completed model 504/1000, 50.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.618073\n",
      "Completed model 505/1000, 50.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.924413\n",
      "Completed model 506/1000, 50.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.444953\n",
      "Completed model 507/1000, 50.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.062140\n",
      "Completed model 508/1000, 50.8% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 3.409112\n",
      "Completed model 509/1000, 50.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.808949\n",
      "Completed model 510/1000, 51.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.769525\n",
      "Completed model 511/1000, 51.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.014307\n",
      "Completed model 512/1000, 51.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.364538\n",
      "Completed model 513/1000, 51.3% complete.\t Training Score: 30.0%\n",
      "(Iteration 1 / 16) loss: 6.021946\n",
      "Completed model 514/1000, 51.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.000336\n",
      "Completed model 515/1000, 51.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.820374\n",
      "Completed model 516/1000, 51.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.182000\n",
      "Completed model 517/1000, 51.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.837059\n",
      "Completed model 518/1000, 51.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.148094\n",
      "Completed model 519/1000, 51.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.215021\n",
      "Completed model 520/1000, 52.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.242706\n",
      "Completed model 521/1000, 52.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.945998\n",
      "Completed model 522/1000, 52.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.611086\n",
      "Completed model 523/1000, 52.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.067634\n",
      "Completed model 524/1000, 52.4% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 14.368622\n",
      "Completed model 525/1000, 52.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.934724\n",
      "Completed model 526/1000, 52.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.102562\n",
      "Completed model 527/1000, 52.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.468578\n",
      "Completed model 528/1000, 52.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.234724\n",
      "Completed model 529/1000, 52.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.219995\n",
      "Completed model 530/1000, 53.0% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 12.019257\n",
      "Completed model 531/1000, 53.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.037144\n",
      "Completed model 532/1000, 53.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.536932\n",
      "Completed model 533/1000, 53.3% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 8.345399\n",
      "Completed model 534/1000, 53.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.589458\n",
      "Completed model 535/1000, 53.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.522194\n",
      "Completed model 536/1000, 53.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.304467\n",
      "Completed model 537/1000, 53.7% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 5.444080\n",
      "Completed model 538/1000, 53.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.417136\n",
      "Completed model 539/1000, 53.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.707030\n",
      "Completed model 540/1000, 54.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.145252\n",
      "Completed model 541/1000, 54.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.799747\n",
      "Completed model 542/1000, 54.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.686061\n",
      "Completed model 543/1000, 54.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.307306\n",
      "Completed model 544/1000, 54.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.802732\n",
      "Completed model 545/1000, 54.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.665601\n",
      "Completed model 546/1000, 54.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.585169\n",
      "Completed model 547/1000, 54.7% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 3.949466\n",
      "Completed model 548/1000, 54.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.573353\n",
      "Completed model 549/1000, 54.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.506076\n",
      "Completed model 550/1000, 55.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.342443\n",
      "Completed model 551/1000, 55.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.533899\n",
      "Completed model 552/1000, 55.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.616881\n",
      "Completed model 553/1000, 55.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.356514\n",
      "Completed model 554/1000, 55.4% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 14.448856\n",
      "Completed model 555/1000, 55.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.929145\n",
      "Completed model 556/1000, 55.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.920439\n",
      "Completed model 557/1000, 55.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.796328\n",
      "Completed model 558/1000, 55.8% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 8.563918\n",
      "Completed model 559/1000, 55.9% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 2.444723\n",
      "Completed model 560/1000, 56.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.246692\n",
      "Completed model 561/1000, 56.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.824237\n",
      "Completed model 562/1000, 56.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 12.923999\n",
      "Completed model 563/1000, 56.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.633982\n",
      "Completed model 564/1000, 56.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.368810\n",
      "Completed model 565/1000, 56.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.169228\n",
      "Completed model 566/1000, 56.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.237637\n",
      "Completed model 567/1000, 56.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 8.052225\n",
      "Completed model 568/1000, 56.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.173272\n",
      "Completed model 569/1000, 56.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.225528\n",
      "Completed model 570/1000, 57.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.291076\n",
      "Completed model 571/1000, 57.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.096741\n",
      "Completed model 572/1000, 57.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 6.846587\n",
      "Completed model 573/1000, 57.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.806125\n",
      "Completed model 574/1000, 57.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.008135\n",
      "Completed model 575/1000, 57.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.580706\n",
      "Completed model 576/1000, 57.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.731992\n",
      "Completed model 577/1000, 57.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.615226\n",
      "Completed model 578/1000, 57.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 8.670593\n",
      "Completed model 579/1000, 57.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.350256\n",
      "Completed model 580/1000, 58.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.907278\n",
      "Completed model 581/1000, 58.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.412929\n",
      "Completed model 582/1000, 58.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.960407\n",
      "Completed model 583/1000, 58.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.553369\n",
      "Completed model 584/1000, 58.4% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 15.531943\n",
      "Completed model 585/1000, 58.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.734889\n",
      "Completed model 586/1000, 58.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.466846\n",
      "Completed model 587/1000, 58.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.623543\n",
      "Completed model 588/1000, 58.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.217668\n",
      "Completed model 589/1000, 58.9% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 14.596011\n",
      "Completed model 590/1000, 59.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.496892\n",
      "Completed model 591/1000, 59.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.907865\n",
      "Completed model 592/1000, 59.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.459091\n",
      "Completed model 593/1000, 59.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.986272\n",
      "Completed model 594/1000, 59.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.899786\n",
      "Completed model 595/1000, 59.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.383429\n",
      "Completed model 596/1000, 59.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.413840\n",
      "Completed model 597/1000, 59.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.999759\n",
      "Completed model 598/1000, 59.8% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 8.407459\n",
      "Completed model 599/1000, 59.9% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 12.776299\n",
      "Completed model 600/1000, 60.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.005825\n",
      "Completed model 601/1000, 60.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.227958\n",
      "Completed model 602/1000, 60.2% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 7.816881\n",
      "Completed model 603/1000, 60.3% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.958169\n",
      "Completed model 604/1000, 60.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.938256\n",
      "Completed model 605/1000, 60.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.560504\n",
      "Completed model 606/1000, 60.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.113815\n",
      "Completed model 607/1000, 60.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.296709\n",
      "Completed model 608/1000, 60.8% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 15.784063\n",
      "Completed model 609/1000, 60.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.338541\n",
      "Completed model 610/1000, 61.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.333261\n",
      "Completed model 611/1000, 61.1% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 3.141784\n",
      "Completed model 612/1000, 61.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.270369\n",
      "Completed model 613/1000, 61.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.374248\n",
      "Completed model 614/1000, 61.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.735858\n",
      "Completed model 615/1000, 61.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.197961\n",
      "Completed model 616/1000, 61.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.024628\n",
      "Completed model 617/1000, 61.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.535385\n",
      "Completed model 618/1000, 61.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.169155\n",
      "Completed model 619/1000, 61.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.838084\n",
      "Completed model 620/1000, 62.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.098442\n",
      "Completed model 621/1000, 62.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.234333\n",
      "Completed model 622/1000, 62.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.834275\n",
      "Completed model 623/1000, 62.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.111642\n",
      "Completed model 624/1000, 62.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.221843\n",
      "Completed model 625/1000, 62.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.981219\n",
      "Completed model 626/1000, 62.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.135836\n",
      "Completed model 627/1000, 62.7% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 10.887795\n",
      "Completed model 628/1000, 62.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 16.708822\n",
      "Completed model 629/1000, 62.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.728425\n",
      "Completed model 630/1000, 63.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.774017\n",
      "Completed model 631/1000, 63.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.074185\n",
      "Completed model 632/1000, 63.2% complete.\t Training Score: 15.0%\n",
      "(Iteration 1 / 16) loss: 11.411944\n",
      "Completed model 633/1000, 63.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.465066\n",
      "Completed model 634/1000, 63.4% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 10.038135\n",
      "Completed model 635/1000, 63.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.408236\n",
      "Completed model 636/1000, 63.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.639377\n",
      "Completed model 637/1000, 63.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.197164\n",
      "Completed model 638/1000, 63.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 12.425633\n",
      "Completed model 639/1000, 63.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.061169\n",
      "Completed model 640/1000, 64.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.213325\n",
      "Completed model 641/1000, 64.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.347771\n",
      "Completed model 642/1000, 64.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 17.430545\n",
      "Completed model 643/1000, 64.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 18.947640\n",
      "Completed model 644/1000, 64.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.739988\n",
      "Completed model 645/1000, 64.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.292078\n",
      "Completed model 646/1000, 64.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.502498\n",
      "Completed model 647/1000, 64.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.919744\n",
      "Completed model 648/1000, 64.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.314651\n",
      "Completed model 649/1000, 64.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.278579\n",
      "Completed model 650/1000, 65.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.374557\n",
      "Completed model 651/1000, 65.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.156432\n",
      "Completed model 652/1000, 65.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.605240\n",
      "Completed model 653/1000, 65.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.782002\n",
      "Completed model 654/1000, 65.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.626811\n",
      "Completed model 655/1000, 65.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.967162\n",
      "Completed model 656/1000, 65.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.654017\n",
      "Completed model 657/1000, 65.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.799808\n",
      "Completed model 658/1000, 65.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.599081\n",
      "Completed model 659/1000, 65.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.776217\n",
      "Completed model 660/1000, 66.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.034576\n",
      "Completed model 661/1000, 66.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.707704\n",
      "Completed model 662/1000, 66.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.422453\n",
      "Completed model 663/1000, 66.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.986497\n",
      "Completed model 664/1000, 66.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.640333\n",
      "Completed model 665/1000, 66.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.832658\n",
      "Completed model 666/1000, 66.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.362815\n",
      "Completed model 667/1000, 66.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.546373\n",
      "Completed model 668/1000, 66.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 6.434349\n",
      "Completed model 669/1000, 66.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.711692\n",
      "Completed model 670/1000, 67.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.822128\n",
      "Completed model 671/1000, 67.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.083131\n",
      "Completed model 672/1000, 67.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 17.562072\n",
      "Completed model 673/1000, 67.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.484006\n",
      "Completed model 674/1000, 67.4% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 13.863266\n",
      "Completed model 675/1000, 67.5% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 13.909872\n",
      "Completed model 676/1000, 67.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.242926\n",
      "Completed model 677/1000, 67.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.477797\n",
      "Completed model 678/1000, 67.8% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 13.537006\n",
      "Completed model 679/1000, 67.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.527677\n",
      "Completed model 680/1000, 68.0% complete.\t Training Score: 50.0%\n",
      "(Iteration 1 / 16) loss: 15.802205\n",
      "Completed model 681/1000, 68.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.338409\n",
      "Completed model 682/1000, 68.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.939205\n",
      "Completed model 683/1000, 68.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.161208\n",
      "Completed model 684/1000, 68.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.457994\n",
      "Completed model 685/1000, 68.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 16.320693\n",
      "Completed model 686/1000, 68.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.441866\n",
      "Completed model 687/1000, 68.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.661386\n",
      "Completed model 688/1000, 68.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.487488\n",
      "Completed model 689/1000, 68.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.593734\n",
      "Completed model 690/1000, 69.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.390431\n",
      "Completed model 691/1000, 69.1% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 8.857241\n",
      "Completed model 692/1000, 69.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 7.646600\n",
      "Completed model 693/1000, 69.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.820097\n",
      "Completed model 694/1000, 69.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.902050\n",
      "Completed model 695/1000, 69.5% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 15.343420\n",
      "Completed model 696/1000, 69.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.995135\n",
      "Completed model 697/1000, 69.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.190419\n",
      "Completed model 698/1000, 69.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.132461\n",
      "Completed model 699/1000, 69.9% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 13.565624\n",
      "Completed model 700/1000, 70.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.763053\n",
      "Completed model 701/1000, 70.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.022155\n",
      "Completed model 702/1000, 70.2% complete.\t Training Score: 55.0%\n",
      "(Iteration 1 / 16) loss: 12.417823\n",
      "Completed model 703/1000, 70.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.093518\n",
      "Completed model 704/1000, 70.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.762980\n",
      "Completed model 705/1000, 70.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.239337\n",
      "Completed model 706/1000, 70.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.766970\n",
      "Completed model 707/1000, 70.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.115919\n",
      "Completed model 708/1000, 70.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.939947\n",
      "Completed model 709/1000, 70.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.750070\n",
      "Completed model 710/1000, 71.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.749464\n",
      "Completed model 711/1000, 71.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.293415\n",
      "Completed model 712/1000, 71.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.730992\n",
      "Completed model 713/1000, 71.3% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 8.399133\n",
      "Completed model 714/1000, 71.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.816816\n",
      "Completed model 715/1000, 71.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.320555\n",
      "Completed model 716/1000, 71.6% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 4.045201\n",
      "Completed model 717/1000, 71.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.449777\n",
      "Completed model 718/1000, 71.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.893074\n",
      "Completed model 719/1000, 71.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 3.934864\n",
      "Completed model 720/1000, 72.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.305562\n",
      "Completed model 721/1000, 72.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.858377\n",
      "Completed model 722/1000, 72.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.922500\n",
      "Completed model 723/1000, 72.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.953966\n",
      "Completed model 724/1000, 72.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.232420\n",
      "Completed model 725/1000, 72.5% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 15.572235\n",
      "Completed model 726/1000, 72.6% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 6.484027\n",
      "Completed model 727/1000, 72.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.982048\n",
      "Completed model 728/1000, 72.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.067376\n",
      "Completed model 729/1000, 72.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.683389\n",
      "Completed model 730/1000, 73.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.307002\n",
      "Completed model 731/1000, 73.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.149338\n",
      "Completed model 732/1000, 73.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.824713\n",
      "Completed model 733/1000, 73.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.077285\n",
      "Completed model 734/1000, 73.4% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 10.617544\n",
      "Completed model 735/1000, 73.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.921822\n",
      "Completed model 736/1000, 73.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.278497\n",
      "Completed model 737/1000, 73.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.035698\n",
      "Completed model 738/1000, 73.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.725951\n",
      "Completed model 739/1000, 73.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 3.629264\n",
      "Completed model 740/1000, 74.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.110989\n",
      "Completed model 741/1000, 74.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.534585\n",
      "Completed model 742/1000, 74.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.469374\n",
      "Completed model 743/1000, 74.3% complete.\t Training Score: 50.0%\n",
      "(Iteration 1 / 16) loss: 6.891414\n",
      "Completed model 744/1000, 74.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 10.396596\n",
      "Completed model 745/1000, 74.5% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.289540\n",
      "Completed model 746/1000, 74.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.338706\n",
      "Completed model 747/1000, 74.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.430364\n",
      "Completed model 748/1000, 74.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.130372\n",
      "Completed model 749/1000, 74.9% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 12.727287\n",
      "Completed model 750/1000, 75.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.820639\n",
      "Completed model 751/1000, 75.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.107978\n",
      "Completed model 752/1000, 75.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.249086\n",
      "Completed model 753/1000, 75.3% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 10.897543\n",
      "Completed model 754/1000, 75.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.431840\n",
      "Completed model 755/1000, 75.5% complete.\t Training Score: 20.0%\n",
      "(Iteration 1 / 16) loss: 10.485259\n",
      "Completed model 756/1000, 75.6% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 15.028933\n",
      "Completed model 757/1000, 75.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.148268\n",
      "Completed model 758/1000, 75.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.332296\n",
      "Completed model 759/1000, 75.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.203050\n",
      "Completed model 760/1000, 76.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.960309\n",
      "Completed model 761/1000, 76.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.569920\n",
      "Completed model 762/1000, 76.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.395489\n",
      "Completed model 763/1000, 76.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 14.384786\n",
      "Completed model 764/1000, 76.4% complete.\t Training Score: 30.0%\n",
      "(Iteration 1 / 16) loss: 9.735182\n",
      "Completed model 765/1000, 76.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 8.914242\n",
      "Completed model 766/1000, 76.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.653340\n",
      "Completed model 767/1000, 76.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.955418\n",
      "Completed model 768/1000, 76.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.324676\n",
      "Completed model 769/1000, 76.9% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 15.836002\n",
      "Completed model 770/1000, 77.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.242305\n",
      "Completed model 771/1000, 77.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.546087\n",
      "Completed model 772/1000, 77.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.521149\n",
      "Completed model 773/1000, 77.3% complete.\t Training Score: 65.0%\n",
      "(Iteration 1 / 16) loss: 12.070220\n",
      "Completed model 774/1000, 77.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.234523\n",
      "Completed model 775/1000, 77.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.361628\n",
      "Completed model 776/1000, 77.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.561684\n",
      "Completed model 777/1000, 77.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.528227\n",
      "Completed model 778/1000, 77.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.390131\n",
      "Completed model 779/1000, 77.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.476101\n",
      "Completed model 780/1000, 78.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 16.043737\n",
      "Completed model 781/1000, 78.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.252239\n",
      "Completed model 782/1000, 78.2% complete.\t Training Score: 55.0%\n",
      "(Iteration 1 / 16) loss: 5.831144\n",
      "Completed model 783/1000, 78.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.596583\n",
      "Completed model 784/1000, 78.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.403226\n",
      "Completed model 785/1000, 78.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 6.645047\n",
      "Completed model 786/1000, 78.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.280690\n",
      "Completed model 787/1000, 78.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.952811\n",
      "Completed model 788/1000, 78.8% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 13.054061\n",
      "Completed model 789/1000, 78.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.364926\n",
      "Completed model 790/1000, 79.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.533392\n",
      "Completed model 791/1000, 79.1% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.597124\n",
      "Completed model 792/1000, 79.2% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 6.462178\n",
      "Completed model 793/1000, 79.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.791065\n",
      "Completed model 794/1000, 79.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.312514\n",
      "Completed model 795/1000, 79.5% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 2.641467\n",
      "Completed model 796/1000, 79.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.056776\n",
      "Completed model 797/1000, 79.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.798980\n",
      "Completed model 798/1000, 79.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.228788\n",
      "Completed model 799/1000, 79.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.570307\n",
      "Completed model 800/1000, 80.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 8.059672\n",
      "Completed model 801/1000, 80.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.484309\n",
      "Completed model 802/1000, 80.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.014517\n",
      "Completed model 803/1000, 80.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.689017\n",
      "Completed model 804/1000, 80.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.332791\n",
      "Completed model 805/1000, 80.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.129360\n",
      "Completed model 806/1000, 80.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.862753\n",
      "Completed model 807/1000, 80.7% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 8.951705\n",
      "Completed model 808/1000, 80.8% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.650894\n",
      "Completed model 809/1000, 80.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.166715\n",
      "Completed model 810/1000, 81.0% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.310159\n",
      "Completed model 811/1000, 81.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 4.732648\n",
      "Completed model 812/1000, 81.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.256197\n",
      "Completed model 813/1000, 81.3% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.401224\n",
      "Completed model 814/1000, 81.4% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.891415\n",
      "Completed model 815/1000, 81.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 4.971695\n",
      "Completed model 816/1000, 81.6% complete.\t Training Score: 15.0%\n",
      "(Iteration 1 / 16) loss: 14.140773\n",
      "Completed model 817/1000, 81.7% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 14.860726\n",
      "Completed model 818/1000, 81.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 15.781183\n",
      "Completed model 819/1000, 81.9% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 15.684089\n",
      "Completed model 820/1000, 82.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 6.827907\n",
      "Completed model 821/1000, 82.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.971597\n",
      "Completed model 822/1000, 82.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.013827\n",
      "Completed model 823/1000, 82.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.242115\n",
      "Completed model 824/1000, 82.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.807327\n",
      "Completed model 825/1000, 82.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.626267\n",
      "Completed model 826/1000, 82.6% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.824571\n",
      "Completed model 827/1000, 82.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.195997\n",
      "Completed model 828/1000, 82.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 10.324604\n",
      "Completed model 829/1000, 82.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.785845\n",
      "Completed model 830/1000, 83.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.794451\n",
      "Completed model 831/1000, 83.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 7.411618\n",
      "Completed model 832/1000, 83.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 15.586194\n",
      "Completed model 833/1000, 83.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.456668\n",
      "Completed model 834/1000, 83.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.150661\n",
      "Completed model 835/1000, 83.5% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 7.006219\n",
      "Completed model 836/1000, 83.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 6.293173\n",
      "Completed model 837/1000, 83.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 7.712754\n",
      "Completed model 838/1000, 83.8% complete.\t Training Score: 25.0%\n",
      "(Iteration 1 / 16) loss: 7.581687\n",
      "Completed model 839/1000, 83.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.236626\n",
      "Completed model 840/1000, 84.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.870755\n",
      "Completed model 841/1000, 84.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.901847\n",
      "Completed model 842/1000, 84.2% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 10.971974\n",
      "Completed model 843/1000, 84.3% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 7.231785\n",
      "Completed model 844/1000, 84.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.418496\n",
      "Completed model 845/1000, 84.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 3.174225\n",
      "Completed model 846/1000, 84.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.046223\n",
      "Completed model 847/1000, 84.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.206056\n",
      "Completed model 848/1000, 84.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.899937\n",
      "Completed model 849/1000, 84.9% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 13.832718\n",
      "Completed model 850/1000, 85.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.138124\n",
      "Completed model 851/1000, 85.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.421466\n",
      "Completed model 852/1000, 85.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 5.113138\n",
      "Completed model 853/1000, 85.3% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 10.582088\n",
      "Completed model 854/1000, 85.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.007302\n",
      "Completed model 855/1000, 85.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.734172\n",
      "Completed model 856/1000, 85.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.590899\n",
      "Completed model 857/1000, 85.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.769707\n",
      "Completed model 858/1000, 85.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.528656\n",
      "Completed model 859/1000, 85.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.609433\n",
      "Completed model 860/1000, 86.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 14.367915\n",
      "Completed model 861/1000, 86.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.601964\n",
      "Completed model 862/1000, 86.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.139636\n",
      "Completed model 863/1000, 86.3% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 9.738187\n",
      "Completed model 864/1000, 86.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.729875\n",
      "Completed model 865/1000, 86.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.489007\n",
      "Completed model 866/1000, 86.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 6.035108\n",
      "Completed model 867/1000, 86.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 2.706318\n",
      "Completed model 868/1000, 86.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.964104\n",
      "Completed model 869/1000, 86.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.354958\n",
      "Completed model 870/1000, 87.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.823227\n",
      "Completed model 871/1000, 87.1% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 14.882434\n",
      "Completed model 872/1000, 87.2% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 12.789629\n",
      "Completed model 873/1000, 87.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.627734\n",
      "Completed model 874/1000, 87.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 9.414803\n",
      "Completed model 875/1000, 87.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.800848\n",
      "Completed model 876/1000, 87.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.215618\n",
      "Completed model 877/1000, 87.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.278518\n",
      "Completed model 878/1000, 87.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.223393\n",
      "Completed model 879/1000, 87.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.300064\n",
      "Completed model 880/1000, 88.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.168292\n",
      "Completed model 881/1000, 88.1% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 15.062014\n",
      "Completed model 882/1000, 88.2% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 11.810817\n",
      "Completed model 883/1000, 88.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.184127\n",
      "Completed model 884/1000, 88.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.812942\n",
      "Completed model 885/1000, 88.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.690823\n",
      "Completed model 886/1000, 88.6% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 11.138876\n",
      "Completed model 887/1000, 88.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 4.566030\n",
      "Completed model 888/1000, 88.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 10.165837\n",
      "Completed model 889/1000, 88.9% complete.\t Training Score: 45.0%\n",
      "(Iteration 1 / 16) loss: 13.640805\n",
      "Completed model 890/1000, 89.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.476595\n",
      "Completed model 891/1000, 89.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.806484\n",
      "Completed model 892/1000, 89.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.135664\n",
      "Completed model 893/1000, 89.3% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 2.937246\n",
      "Completed model 894/1000, 89.4% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 6.916467\n",
      "Completed model 895/1000, 89.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.646427\n",
      "Completed model 896/1000, 89.6% complete.\t Training Score: 30.0%\n",
      "(Iteration 1 / 16) loss: 13.259880\n",
      "Completed model 897/1000, 89.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.687501\n",
      "Completed model 898/1000, 89.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 4.551689\n",
      "Completed model 899/1000, 89.9% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.781946\n",
      "Completed model 900/1000, 90.0% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.134318\n",
      "Completed model 901/1000, 90.1% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 7.400680\n",
      "Completed model 902/1000, 90.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.763796\n",
      "Completed model 903/1000, 90.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.940392\n",
      "Completed model 904/1000, 90.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.495578\n",
      "Completed model 905/1000, 90.5% complete.\t Training Score: 40.0%\n",
      "(Iteration 1 / 16) loss: 10.079520\n",
      "Completed model 906/1000, 90.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 9.714434\n",
      "Completed model 907/1000, 90.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.969101\n",
      "Completed model 908/1000, 90.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.867790\n",
      "Completed model 909/1000, 90.9% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.957846\n",
      "Completed model 910/1000, 91.0% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 16.420302\n",
      "Completed model 911/1000, 91.1% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 11.561025\n",
      "Completed model 912/1000, 91.2% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.620135\n",
      "Completed model 913/1000, 91.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 15.392343\n",
      "Completed model 914/1000, 91.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.130615\n",
      "Completed model 915/1000, 91.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.546007\n",
      "Completed model 916/1000, 91.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.547704\n",
      "Completed model 917/1000, 91.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.424540\n",
      "Completed model 918/1000, 91.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 17.588136\n",
      "Completed model 919/1000, 91.9% complete.\t Training Score: 40.0%\n",
      "(Iteration 1 / 16) loss: 8.990525\n",
      "Completed model 920/1000, 92.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.535595\n",
      "Completed model 921/1000, 92.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 9.803317\n",
      "Completed model 922/1000, 92.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.520171\n",
      "Completed model 923/1000, 92.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 10.170828\n",
      "Completed model 924/1000, 92.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.322001\n",
      "Completed model 925/1000, 92.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.106188\n",
      "Completed model 926/1000, 92.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.581034\n",
      "Completed model 927/1000, 92.7% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 13.194451\n",
      "Completed model 928/1000, 92.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.830118\n",
      "Completed model 929/1000, 92.9% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 5.098469\n",
      "Completed model 930/1000, 93.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.181552\n",
      "Completed model 931/1000, 93.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.367991\n",
      "Completed model 932/1000, 93.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.447508\n",
      "Completed model 933/1000, 93.3% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 11.543218\n",
      "Completed model 934/1000, 93.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 8.517126\n",
      "Completed model 935/1000, 93.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 5.807871\n",
      "Completed model 936/1000, 93.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.104491\n",
      "Completed model 937/1000, 93.7% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.475624\n",
      "Completed model 938/1000, 93.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 3.829471\n",
      "Completed model 939/1000, 93.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.109251\n",
      "Completed model 940/1000, 94.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.387519\n",
      "Completed model 941/1000, 94.1% complete.\t Training Score: 60.0%\n",
      "(Iteration 1 / 16) loss: 12.283890\n",
      "Completed model 942/1000, 94.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.936353\n",
      "Completed model 943/1000, 94.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 6.332394\n",
      "Completed model 944/1000, 94.4% complete.\t Training Score: 20.0%\n",
      "(Iteration 1 / 16) loss: 6.209761\n",
      "Completed model 945/1000, 94.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.172860\n",
      "Completed model 946/1000, 94.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.943997\n",
      "Completed model 947/1000, 94.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 15.725766\n",
      "Completed model 948/1000, 94.8% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 12.039421\n",
      "Completed model 949/1000, 94.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 7.546830\n",
      "Completed model 950/1000, 95.0% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 4.638117\n",
      "Completed model 951/1000, 95.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 11.964907\n",
      "Completed model 952/1000, 95.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.016020\n",
      "Completed model 953/1000, 95.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 11.681633\n",
      "Completed model 954/1000, 95.4% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 16.612278\n",
      "Completed model 955/1000, 95.5% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 3.583080\n",
      "Completed model 956/1000, 95.6% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 9.095396\n",
      "Completed model 957/1000, 95.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.524993\n",
      "Completed model 958/1000, 95.8% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 16.385343\n",
      "Completed model 959/1000, 95.9% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 10.094831\n",
      "Completed model 960/1000, 96.0% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 6.043055\n",
      "Completed model 961/1000, 96.1% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.519791\n",
      "Completed model 962/1000, 96.2% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 16.376336\n",
      "Completed model 963/1000, 96.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 4.821384\n",
      "Completed model 964/1000, 96.4% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.227004\n",
      "Completed model 965/1000, 96.5% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.503229\n",
      "Completed model 966/1000, 96.6% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.015112\n",
      "Completed model 967/1000, 96.7% complete.\t Training Score: 70.0%\n",
      "(Iteration 1 / 16) loss: 15.928803\n",
      "Completed model 968/1000, 96.8% complete.\t Training Score: 35.0%\n",
      "(Iteration 1 / 16) loss: 5.177733\n",
      "Completed model 969/1000, 96.9% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 13.305520\n",
      "Completed model 970/1000, 97.0% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 12.849762\n",
      "Completed model 971/1000, 97.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 12.447381\n",
      "Completed model 972/1000, 97.2% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 8.459252\n",
      "Completed model 973/1000, 97.3% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 14.605051\n",
      "Completed model 974/1000, 97.4% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 5.471942\n",
      "Completed model 975/1000, 97.5% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 16.074928\n",
      "Completed model 976/1000, 97.6% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 13.341012\n",
      "Completed model 977/1000, 97.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 13.805909\n",
      "Completed model 978/1000, 97.8% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.789783\n",
      "Completed model 979/1000, 97.9% complete.\t Training Score: 100.0%\n",
      "(Iteration 1 / 16) loss: 16.912764\n",
      "Completed model 980/1000, 98.0% complete.\t Training Score: 55.0%\n",
      "(Iteration 1 / 16) loss: 7.620994\n",
      "Completed model 981/1000, 98.1% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 9.042047\n",
      "Completed model 982/1000, 98.2% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.856307\n",
      "Completed model 983/1000, 98.3% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.726867\n",
      "Completed model 984/1000, 98.4% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 3.774575\n",
      "Completed model 985/1000, 98.5% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 5.365308\n",
      "Completed model 986/1000, 98.6% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 14.262864\n",
      "Completed model 987/1000, 98.7% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.755729\n",
      "Completed model 988/1000, 98.8% complete.\t Training Score: 75.0%\n",
      "(Iteration 1 / 16) loss: 9.947681\n",
      "Completed model 989/1000, 98.9% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 12.924357\n",
      "Completed model 990/1000, 99.0% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 3.144674\n",
      "Completed model 991/1000, 99.1% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 11.877324\n",
      "Completed model 992/1000, 99.2% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 5.129618\n",
      "Completed model 993/1000, 99.3% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 15.174379\n",
      "Completed model 994/1000, 99.4% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 8.520341\n",
      "Completed model 995/1000, 99.5% complete.\t Training Score: 95.0%\n",
      "(Iteration 1 / 16) loss: 8.670508\n",
      "Completed model 996/1000, 99.6% complete.\t Training Score: 85.0%\n",
      "(Iteration 1 / 16) loss: 12.506120\n",
      "Completed model 997/1000, 99.7% complete.\t Training Score: 90.0%\n",
      "(Iteration 1 / 16) loss: 7.906184\n",
      "Completed model 998/1000, 99.8% complete.\t Training Score: 80.0%\n",
      "(Iteration 1 / 16) loss: 13.015572\n",
      "Completed model 999/1000, 99.9% complete.\t Training Score: 50.0%\n"
     ]
    }
   ],
   "source": [
    "#create the models and train on overfit data\n",
    "\n",
    "for ii in xrange(num_points):\n",
    "    mod = ThreeLayerConvNet(num_filters=16, filter_size=3,\n",
    "                       hidden_dim=100, num_classes=10, weight_scale=0.025, reg=reg[ii],\n",
    "                       dtype=np.float32)\n",
    "    \n",
    "    solver = Solver(mod, overfit_data,\n",
    "                num_epochs=4, batch_size=5,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': lr[ii],\n",
    "                },\n",
    "                verbose=False, print_every=100)\n",
    "    solver.train()\n",
    "    solver.train_acc_history\n",
    "    training_score[ii] = solver.train_acc_history[-1]\n",
    "    print \"Completed model %d/%d, %.1f%% complete.\\t Training Score: %.1f%%\" %(ii, num_points, (ii+1e-5)/num_points*100, training_score[ii]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAADwCAYAAADiv7d9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXu0JddV3vutqv067+7T79ajZcuWLBnFBNuSH4BFTLBj\nDPa4HugSQwKGm5gYDwiPBJxLoAFzARNMnGtzcRJHw45xYhHlxmC42MEY4ifYMhbClvXCeqtbarW6\n+zz67LMf6/4x56x9atZep2q/9z49f2P0WL1WrVq1qnbVPrW/mvVN572HYRiGYRiGYexVoklPwDAM\nwzAMwzBGid3wGoZhGIZhGHsau+E1DMMwDMMw9jR2w2sYhmEYhmHsaeyG1zAMwzAMw9jT2A2vYRiG\nYRiGsaexG17DMIwR45z7Zufc3ZOeh2EYo8E593Xn3N8LLLPrfwqwG94pwzn3oHPutHNubkfbDzvn\nPjnJee3EOfcDzrlPTXoehjGNdPvD573/tPf+uknNyTCMYjjn3uic+4Jzbs0595hz7g+dcy8fZEy7\n/qcDu+GdPjzoc/nnXdqHhnMuHmR1DHk+hmEMnwGvc8O4pHDO/SSAdwJ4O4DDAK4E8B4A3zXJeRnD\nwW54p5PfAPBTzrllvcA59zzn3Medc0875+52zn3PjmWvcc59yTl33jn3kHPuF3YsO+Gcazvnfsg5\n9xCAT3D7S5xzn3HOPeOc+yvn3Ct2rPODzrkHnHMXuPyHzrnnAfh/ALyUfwGfHeWBMIy9gHPuFc65\nR3bUv+6c+ynn3J187f0X51xlx/LX8vX4jHPu0865G3Ys+xnn3P18Xf6Nc+71O5b9APd/p3PuDIDk\nO8AwjDD89/YXAbzFe/8R7/1F733Le/9H3vufdc7d6pz7pR39U9c0c6Nz7iv89/l9ck13uf4vd87d\n7px70jn3lHPu341lJy9x7IZ3OvkigD8D8C92Njrn5gF8HMAHARwE8L0A3sM3oQCwDuAfee9XAHwn\ngB9xzn23GvtbATwPwKucc8cBfBTAL3nv9wP4aQC3O+cO8LbeBeBV3vtlAC8D8GXv/dcA/AiAz3nv\nl7z3q0Ped8PYq+inIt8D4DsAPAvACwD8IAA45/4ugPcB+CcAVgG8F8DvO+fKvN79AF7O1+UvAvig\nc+7IjnFv4j6HAfzKSPbEMPYeLwVQBfA/elhHX9NvBPD3AVwN4FoAP6f7Ouci0N/dr4MU5MsA/Nf+\npmz0gt3wTi+/AOCtzrkDO9peC+Dr3vsPeOJOAP8d9IcT3vv/5b3/Cv//b0AX0St2rO8B/AL/cq0D\n+H4Af+i9/xiv8wnQzfZruH8LwA3OuZr3/rT33oLuDWN4vIuvq3MA/gDAN3L7PwHwO977L/J1/p8B\n1AG8BAC897d770/z/38PwH0Abtwx7mPe+9/23rf5OjcMI58DAM5479sDjPF/e+8f52v6VwD8wy59\nbgJwDMC/9N5vee+3vfefHWCbRkHshndK4RvXjwJ4247mEwBe4pw7y/+eAf2iPAIAzrmbnHN/yo9J\nzgF4M0gJ3smjarxb1HgvB3DMe78J4H8H8M8APOGc+wPn3LWj2FfDuEQ5veP/mwAW+f8nQCFNO6/L\nywEcBwDn3D/eEe7wDIDnI32d68eshmHk8zSAg6zA9svOv68Pga9ZxeUAHhrwxtroA7vhnW5OgtSe\ny7j+MIA/896v8r/93vtl7/1befnvgh7HXOa93wd6FOrUmDsfwTwC4ANqvCXv/TsAwHv/P7333wHg\nKIB7APz7LmMYhjFcHgHwK+q6XPTef9g5dyXoOnwLt+8H8BWkr3O7Pg2jdz4HepLy+sDyDQDzO+rH\nuvS5Ysf/TwB4vEufRwBcOeCNtdEHdsCnGO/9AwA+DODHuOkPAVzrnPt+51zJOVd2zr1oh/K6COAZ\n733DOXcjSP3dib75/SCA73LOfYdzLnLO1Ti4/rhz7rBz7rs5lrcBig+WX6SnAVy+I6bQMIw0Fedc\nVf4B6OVa+Q+g+PsbAcA5t8AvpC4AWABdh2f4mn0TgG8Y+uwN4xLDe38BFEr4Hufc65xzc/x39tXO\nuV8H8FcAXuOc2++cOwrgx7sM86POucucc6sA/hW6x+b+JYAnAPyac26evyNeNqLdMnZgN7zTh1Zn\nfgn0q9J779dBAfHfC/rl+DiAXwMF2gPAWwD8snPuPChY/sO7je29fxTA60AX5lOgRzA/DTovIgA/\nCeAxAGdAL7v9M171T0Gq0inn3JMD7Kth7FX+EBSmIP9+HunrL6jCeu/vAD3ZeTe7oNwL4Ad42d0A\nfhPA5wGcAoUzfHoE8zeMSw7v/TtBf/d+DsCToKeqPwrg/wUJRH8N4EEAf4zszawH8CHQi+X3g2Lr\nMy+NcijDdwF4Lo//CIBbhr4zRgbnvT39MgzDMAzDMPYuAym8LPV/zTl3r3PuZ4Y1KcMwRoNds4Yx\nO9j1ahjDo2+FlwOu7wXwStCj9S8A+F72aTUMY8qwa9YwZge7Xg1juAyi8N4I4D7v/UPe+wYonuV1\nw5mWYRgjwK5Zw5gd7Ho1jCEyyA3vZUj7PT6Kjn2WYRjTh12zhjE72PVqGEOkNOoNOOfsrTjDUHjv\ntUXcVGDXq2FkmdbrFbBr1jC60e2aHeSG9zFQHmjhcm7LsHTg2Vg5dDUAYOXQ1cn/p4GHv/pxXHn9\ndxTq+75/+84RzybLu9+5hrf+5FLXZXfVu/leD58bqk90bd9tbpNmmub2l5+r4y8/t53U3/Nv1yc1\nlULX7Cte8QrcfPPNAICbb745+T8AfOOP0jXQLjsukS5L6bov0d/idqzq4krLdR/z3+wSWT27MpUR\nL4/iFi0utXHmw5/Ese/7VgBApdTiskll3MJcqQEAqMVS0rI5ri+U6qn6fESfzXxM7UvRFrdTfYGX\nL0Sy/CKN65pctpLy371zDT82JeedZprnBgxnftueHlo2+OFlQ+qeTsBtxKl6zdE5cDTeBAB8YesK\nfPUvLqB0//cmY/7iL/7iQHMagMJ/Y3e7Zl/8g93/bgVv4QPtubf8geWPf+ljOP5Nryo+Th/b6Hec\nJ774MRx70at27ztBpnl+0zS3tcfvx/e98HBSD12zg9zwfgHAc5xzJ0Amyt+L7nmjsXLo6sI3lYax\n17jxpVXc+NJqUp/gDW+ha/bmm2/GyZMnxzw1w5gOrr9pGW/8/pNJfYI3vIX/xto1a1zKLB1/Dk6e\n/MmkPvQbXu99yzn3VpDJcgTgfWyKnqG+z+HCibjfTQ2Fn3/LB7u23/bvHsctP/Z0oTHGpaju5HTL\nT2S7Owltv9e5hZRiYzz0cs1qbvzHvwkAqF9BilmrxmNGrMxGUk+X7TIruKrUSm7MZYkV23KZS1Z2\nq2VWU0tNXKxu47KV8wCA+dJ2qlwsbWOBldpFUWzjLa5TucwKrSi4mnbg1YaNdjVVCq0dstMTrcdx\nR/04jeMj1W+yeX4ebT6Kz29djpgTJkaOjz3nwIi5HvFyqQvSTy9P2pN6pz0KjNFZp1NvIsKW7+/v\nhKjsFd5eRZJCFlQE79o+CgB4pLHa1/ZHwSDXKwDc9H10zYKfxgxN0e1DAU4tK/KZTG0ASZ8MEnQy\n7oCVGTv2fOkXYqAYXu/9HwO4Nq/fwuXPGWQzI+X5N03vIz5guuc3zXO78aWVSU9hKilyze58HDqN\n7HvBFfmdJsT1U3xNXHfT8qSnsCsvfkk1v9MlRtG/sdN8zS4em54QRs3i8emdG2DHbtiMPNOac87f\ndt83jXQbg/DTnx59Rr+vv/o/jnwb08Dt69P9B3VauOW5X5ral2Ccc37nd8I/uPqnAQCN4/upXKTf\nyM0FjoWcd6myKeUcuE5jtZKSld05VnDnOK52jtTWlTlSYQ/UNgAAh2sU/jHHcbSliNYv88/6TBk1\nE/Wws6zZtV7JjEHtW54CjM+1FgAA51u0M+ssa5/nnVtrUH2tSTdq6w0qNxsVLmmc+TLHCpfTavRS\nmRXoEivPXIoivcJxpaJE1yI+VhJb7LbTy3k/Fng/qnyGNfjjFK1Vx7m2+VTcTuoR19Pxrq1kPVX3\ndE6I0i31xg61tuW7q9sh1bsduDzC/UPj0zhahS4nijAdq22e8wNbFAf4Gy/4vWQM59zUXq9A9pp9\n5bdSNtvmIp1/nXh7LiWePmLlVz2VEYUvWe4Cy126rpXBUR6x3Nf09PJA/6Kv+/WqdgeZ2rNoBIxa\nmebx5SHSHe/rhDSErtnJPmMzDMMwDMMwjBEzclsyAPidH37DODbTF89BDwEgzCve87me+r/9zPN6\n3sZe4JaVOyY9BWNQmnR9+BKrd0v8tvsiq4GsFolSEm+xktag/uUNUZG4jCMuS9xOqmg9WgQAnObx\nTvFP8b+JxcUB6VJUJr08ApC0iQTA+yJ1Lh3HH7uYVWduj1hFjnh5zMuTkne2xPUSxxlLu8Qd769d\nTNVLEiPL/Rp88NaapBTX2eLiQkT1Jx2FR1SjZqoUdTKJuQ3F2io1U2JrQ0q3KMiJIo6WWl5PrS+K\nchnp4yK0vEObD74oraLctlS7IEptZ3nUtb2zDV4OtZ5qv8Dq/FcuXg4AuNgi9XNRxXvLZzHLnHsu\nPYEo1fn8Tp8eWbWS68nHlyhnvnt/TUHV0rtdOhYeY7C5FFadVb+QElxYxJTxiq7QoxLct5o+QsW5\n1zkF1XYfWK6fPBTAFF7DMAzDMAxjTzMWhXc3/ueHb530FKaeNz38LZOeQk+8dvVOAIO7Wkyzq8M1\n5YVJT2EstFdIeb14iOJS68sc37nMii8t7sTqzrHP7jyphBGXtXmOW+VY3dU5ik89yDG6x2oXqKyc\nAwAcLz8DALiydBYAcKJEaulKRPMou/Tb/A1PamMbbTQ8SVotlgYaHN/YSvryvnF9O1EDJQY1rRYm\nMawqRjVUz4ttbbH0IeqjxI+K+pldL+blUWr8LTYzTubdlnnS8mY7StVF4Q35D88rv2Ept/h4VnSs\nc6L00ngVLwpym9s7T89EWYmVxJK0p5sRKzWw06+7bLTB297kY6jdHsrsAvLyuQcBdOKbFxyN/Eeb\n9CLk1zaOAAB+9SuvAQC87fl/1HV704xcm/HTfC2WlEtDKAYXqh3dl/ft0ztEBk610e/641ovoGaG\nSI5Hr5+B2s4wP8NhpUPR44Tm+IK3/hYA4M53/0RwLFN4DcMwDMMwjD3NWBTex368EVx2/We/fxxT\nGAo3Xf7QpKcwE3z07AuGMw6GM870cf+kJ1CY6DwpsOV1iidtzNFvZA73BIuDSYxu541tViW5usWl\nvDjbaNE45+sUM/nghQPp7QbkAZ1FVVwbIpYqnPPJupmS+5Si1q7LO+1pxVK3x5n10jGyoX0IEXIm\nyEM7F4TGabL7RJ2V4XOYp/6ZuNjhyTwh94ThjU9zlWPdiXduqDqVomZLljzpJ+NscWxvyFViFtg8\nRseidlakXCp0GKlWBeVjD8VKhvCuUDdjEIp+lQyoqk7lZ5gXTy1W8AW+b2f3qjYMwzAMwzCMAoxF\n4X3jNV8cx2ZGznW1xyc9BSOHdz/0bZOewp7Cn6fY2tLFQwCA5hx9ZdT30fLtVVI124co/vPwQep/\ncJ58dI/NUf3EHGUzlGxnovyFnAT0r/UY6lVzadevoO8gCqzTWXd3RSC0zWT8XbZN63cff7c5A0Xm\n3d2VIeRQ0Ao4HHScD6SfC6zXXUEOOSh0c1TQ8cftzFzT9fC2tNtDul0QFftiu5LeN6/GUcdEvJR1\n+yzRvoyvsXsCjhNF/XKn6RBM01ymiXFnYRslOS4NIeRr3IUDCRJM4TUMwzAMwzD2NBN3aZgl7t46\nPukppHhg89CkpzB23nbsj3dd/t5rPjSmmfTPdZOeQA/4JsU6osUqIr/e3qpxfZG9WqvsxlCi8hC7\nLxypksK7v0SKbxLTySql1DcDTgTDUNqiAWWQPEU2d/sDrh/MIhZoDx2zov2D/XrMfgaEM+JVE8/f\n7ssrKjueOEFks+Qpb2LxBA585vJZrLU5dnybvkMf3qYY8pUyuYE0vPaNmB3iEu2j/hiDb7v3qvD2\nmuVsGOwlJXOvMehXdN55GILPCTmP4+38VUzhNQzDMAzDMPY0Y1F4P3H62nFsxmA++fyPANibGd5u\nO//CSU+hL2Y265z4oXLZohBHcGgkXJXUpJVFUsYWK/QW/FNbZND7dJ38iv8al6WGzVNdQ6po6E1c\n7biwcxshd4X++6XjjHWsr55LMC7ZpR0mdD3Tz6XVS1FJk35qfnnx0J3tdd/fzvrp7WrFO1LjCS0f\nZeKBk2WZeN90HLEgSqt4DuuYXalrr+J59hBe4phx8RReiug8XXAkBz2vSu9lfGPtYQDAn27Q85fz\nzXnMKo2L5a7t2oVBZ1bT/aZSVbVY3umj3/Nk0OxzUuevHdcylwbDMAzDMAzjEmcsCu/ZP7wsv9OQ\n+fm3fHDs25wWbl9fBjA5V4lpzpA2Ll7/hTen6h/Ci3bUTo51LgMR0W9iH7Mip8Qjd5YazlxYBQA8\nVdpPC2KfLiV0N6af4y5i39xYqau8POLlcZxWKUsxx2ry8rLUXadeEucHXib1StxM1atc1x6u4tMr\n9Zp4ujpV51LiS2uZejqoTMeVajeGUKxwZr2MS0N314Zwf63k6v4Bd4nM/LUSna63vMMae/9utunR\nwAWOnW0k9TleTo8M1lu0XBTdervUtdzm8iL75m634lT7qw59FQBwdflJADtjfPk8UR7LZW4/XqZM\nf880ZjeTYukMHZOoldOR0aHZuXamPaqsfdk6j0rJnXGFeJzZ7ISRZbXL83uWJxHt7qXAl3yh890U\nXsMwDMMwDGNPMxaF9+i//ew4NpPmLePf5KXKqBTdu+rH+l53WNne+mW3rHz3jHEe/fL3o+8BAMTL\n9LSg+hD56F6xQfWtg6TE1fdzjCWX27Q4eUM8edmd621WdKXdJ+1cRmp50j+tFHeU47RS7OJ2RzWO\nuqvFUkqWtpK0c70cpRXiMksHlUQxTtcrSTavtDIsCrBsJ08p7jgSbKeWi2IszgSRT8fMNkAHK+zC\nEHB5yHFzSLanYnS1I4KwxmqtqLib7Sq2Pf2JkZjbBtcl5jZUSv+VEsXcXlOj75h90WZqn8sQVwfJ\nbsdqPrT7gyi5vDzZF/A+EleU6Tz/sr+y67GZZtqnngsAWHyY/vhV1ljy4n1sl/gpTXLtUV3C9DPq\nYcivt8dMbHkKYVfVcljxwwHVcGSMWIEdWG3thUGzu4XcF1R/rdxGHIvLly6iJn+fs2GQ8+wQVKGr\ntsknsMXwGoZhGIZhGJc8U+fD+0/v/dtJT2HsTJu/b69M4/yvnn9q0lPYG0RplwaJ5YVWhbgs0Uvx\nSVyVlCzswSXj+NR6otS2q6zoVjjWt8oKXSXt9ztXIdVzoUJqqLhDLJe3sK9CquC+EqmB+8vkAbwa\nU1lT7gbaGUATVEhzMpEl/VRGssz43F6XEhSDudbePVY35BKh3Rc67SFXie4xvnq/tbKs+wuiwh6I\n1zN9QvHHOlvcufZ8ej2lMouCqx0pEh/fpN49VleUXXkAIeF/4t4Q8hyeZu5t0Pm9cIr2RtRArcwm\nihorZYk1tnRzat+dXg7VoNrVeppdD+2wPF2LMmzFdNzOFiM8TQNfV0Eyrh/KDSS59FU9pOjG23zt\nb/P3WSN9vvol2vlI/rYUOPam8BqGYRiGYRh7mrEovN/y11uF+w5LLZwl39Nhx8AOEvtqGAB2+O9y\nJrRrKCPVxhH6yli/kpZfvJzU0hue9yAA4LmL9FZ86E1/jcS7ZjJuiUNCkklL90vHwe7MvNXJyiVq\nX0uNxTG1vFxURVF6JfOYjnHteL9qBTftKavbswpwlFqe9E+yywXG6VVyGRFZT12NBIn2vw3xzdXK\ncFbZ9aofK7jKW1gruxU+v8t8bNdYvQ59ZrPA7567EQBQX+LzSLyyWUnTPrxSz2RkU2/BjzVudNzM\nnpDfGwN8dpnPPSeGWxTarKuCT9Wz7gt87YrC20gru3FdFF7OzlmmE1aUYNcq/iHO3lVtGIZhGIZh\nGD0wdTG8IXr1lN3LKme/KvgDm4eGsv3Xrt45lHGMKYaVXbeyBAA4ey37opLdLpoLHBO5QkrcqXXu\nd5FiL8XhQLxutaNBhX/Oz8WNdL/E4SCt4M6zp632vk3UUFYEt9plrGGu0C5qFa+j8Kazg4VidHVs\nbp7Sm/RLlNyQwptWdPX2BJ1JLS9zm87Y1hlHZ2jrnrFN0LHDcaKYp/2IdQxxL2ywT68gCv5CvAYg\n67rQiU+WmF/eNz7EYh9dFmWXz+8yq9Hn2hK7mz7ms8SHvvJiAECJn75Uz1J76WJaQRP63cPcQzML\nh25EqnWvavjIT7NBxtf7IvXAmO3A3WTpIsfaipLbDCi+3qfqyXsj/B5J54mES/WLCrgzCKbwGoZh\nGIZhGHuamVF4R+0EMKmsZP3Q71xD6/XqWTtqj1tTkCeP41/RrYNkrLu9j9oXvukMAKBWJgV2vsxu\nCSVSyOa5XCpT3H5ZqYpaHUwyrAXaBcm8JT6tm0grgDvVy6KKZUipFGWyrCSxznoqflQppkWVTe1J\nu8VZycS7ts77vCX9JNuY3/1ru50oynGqPfLdlZDs/HUGtd2V4WS9Lssl1jrvWGsHiSRml5VdfmEb\njzX3pbaxHNF5thqTM8SqPEFgdShRevmYREnsbvrYaJp+9+XTyNwd9HRl66BIZuxPqpS0jMMK0u09\nMwuKrqZveTtncWjcScVBD7LdosdIuTFoOHkimvPpE08cfUpb/P0s5jkldmyR7J4luhYj9t0VP+nk\na1CE4QLyrSm8hmEYhmEYxp5mLArvJ05fO47NDMQnEJ7jW098cowzGT+jVlRHlYltlNx2/oUjHP1L\nIxx7SHCMY/0A/TzfXuGsXhcWAABrHJMbs59uqcQuCRK7ywrwMvvj7q+RAqfVw5CbQ0YtDPXrImEM\na0ytSpeTbF5pNVKUYB0rW1bZvzoZynygXVRNOnYLpXqqPaQsa4/akHdtXmxuiJBjQchXOJTBDSie\nDU7U7ieb9IThmSadd2cai7xt2sYNC48CADb8BQDAOVZ8xU93iWWjVfZ5XnT0ZCDiOV70HLur5r5U\nKu4sNC0sPkp7Ud/Hyi5npsr45gbQ7gzjYiLh0uOOnR1we9MYUp4bryzLlWuDHIsWB9aLYqsPUsb1\nQT2hiunSTWKCi4jZpvAahmEYhmEYe5qxKLx7XSEtyjRmJBuEorHE/TpmjDpW2AgTLZDTQX0/fUVU\nz9JvY3+B2tscZ9WoUVmf41/ZNVYrubxQo5/hp2JycSiJW4MowhGrnLHUeTnXa+ziIK4O4t4grg5z\niXtDx91BXAKqyuGhxqpfxXX3cpV406JKqfbHbXBcqMTmbvt0XQhldtMqp47t1eRlVEvqSiHutBeL\nQdauFTIvUX6Tepfl7Uwb7bvEI0u8cWgMUXJ1XWJsP3fhaqq349R4coy3eTtbTY6HblH9t579ewCA\n46W0t7Ls0+WVZzBrbB6muVd56uJvKn68ebGWow4zHadKWVh9vMTpyVWi12MW6q/atT90xg2Cy4sH\n0t+P1WeoY2VD3B/yp2QKr2EYhmEYhrGnGYvC+2u/+n1DG+tn3/a7hfr967/+7qFtc9r45b/z+32t\nN2uxtDccG95833zvG4c21iXBQTbc5V/b4unZYovb5pz8LEeqbEWsBnLMZCPmN2y53myl336X/o02\nlbGjryRRfC9GZW7n+FZuL6l4Wl0CO2Nxc9wEZN1AfHHx/t0dJkI+trpfJtucyjqXaeesY5VQFjqX\nzUK3s59kLeusF/Dn5bKSKMqE9N5KlOyI66xwI+64a7D6vcVyo6jWiYqduHCUUmPU29371Vm9FAVX\nxB2t7G7z+bbNCvDzV+g75b7GQQDAFaWz6MaR8rmu7dNM7Rn6RORjbMdKUs1xZ8hzbRhUoR1o9UnF\nsA5pu5OKwS2s4BbpNy5VXJ2PLZUxsElmJNheZreHOpeN/CD0XIXXOXe5c+5PnXNfcc7d5Zz7MW7f\n75z7uHPuHufcx5xzK4V3yDCMkWDXq2HMFnbNGsZ4cD7gzZh0cO4ogKPe+y875xYB3AHgdQDeBOBp\n7/07nHM/A2C/9/5nu6zvr7395PBnbiR89WUfnPQUjB6Ij90P70fzm38Y16v3Hq8+8E8BAP7KowCA\nxn6SdpsLrObNR6myycpvi5XfZqIEc7wrl20V61uaYzVyjuJrRdmNWRF24ogQ6axi3dtLrp2sU+Jl\nJeUjW+qyDpB1WyhxPU76pVVlrbjqdu3WEHZtaOesx7HFgVjjjtKbHl8U3E5duU4krhBp5bbMZ6Z2\noo2Vt23Srjxu4y6y2JanuTT4741Ybjb4z882q8N1VnK3VXxwR/kVr+J0u453PtciGUjcHdab1dS+\nH6ucBwD8vYW7AQBVPnanW+QCcapJ95ZvfO5fwjk3susVGN41e9P3/SaAHX6kiVKmnsZA2vVA3ec3\njsxqQz+641JUx7SdaXRpyKPXrHMZ9PqJ4kv/kayfiw9Tx+oF+h77zO0/HbxmcxVe7/0p7/2X+f/r\nAO4GcDnognw/d3s/gNf3si+GYQwfu14NY7awa9YwxkNPMbzOuasAfCOAzwM44r0/DdAF65w7HFrv\npssfGmCKRh5vevhbRjr+1fNPjXT8S4/7x7KVfq9XAECLFC/XpF/N4pW4tZ+UtIuHIi5ZsTtIquPq\nMVLObjz8GIBstjJNNx9dIBs322kPZAvbxVM27Mvb21ih/sl6PGed6UycB7ZQ7to/s52cYLngepMy\nUh0Bg2bLW43XAQCHSmuqf3q8h5v7AQDPrzwJIOvWMG4GuWaT05NPg6zSq+qRat9LjCvedEzb2Ysf\nUS56p/lYR/xYqHqWnyZyTG95M3/Iwje8/KjlvwH4ce/9unOZb//gR//l//BXyf+PftNRHH1hfzZV\nhjGLfP0LZ/DgF54e6zYHuV5PnjyJ+7coOcbq+jdgdfHE6CZqGFPGnZ/fxGc+SzfMDxw4ObbtDnrN\nPnrXZwEAS0euxvKR54xuooYxZaw/dj/O3EdC0smT68F+uTG8AOCcKwH4KID/z3v/Lm67G8DN3vvT\nHIP0Se+NY4SoAAAgAElEQVT9dV3W9f/4L97U104Yo+XWKz816SmMnNvXlyc9hQy3PPdLo44JHOh6\n9d7j1av/BzUcOQQAqF9GMY2bR0ilFM/PLVZ4tw9wvOgSRWcuLFKmqgML9LP7sgVSfkXxnWN/XfHR\nlbhaTT9qa0gBzYwxYnmm6Dz6RWd2E99hcWeQGOBapj3t4qCXS6yvxLXWRBV1st00oVjfnX3lSGxL\nDK/X7eJlTKX47epYXu39KzG82hNZvIOD8c+qXuNyrU2ZBR9j5fcfPffzI4/hBYZzzb7kjRzDq5Xc\nTD3g3hClS2HkCvAlKV/m0OMxmSqP434JjZuzby1+6aB2jr5N/uKDP9V/DC/znwB8VS5E5vcB/CD/\n/wcAfKTgWIZhjBa7Xg1jtrBr1jBGTG5Ig3Pu5QC+D8Bdzrm/At2H/ysAvw7gNufcDwF4CMAtoTHe\nduyPcydy2/kXFpyyMSzefuZ5PfW/ZeWOEc1kdNxQ3Zj0FMbKMK5XAECJvxo4ljdqpT0+JTQ3Fg/E\nC6S4cVpzrLepXX5kS3l04QIA4GCFHjtdVTtD7SVSgA+VaPkCZ0UrJ04EaUcBcRJo8fYaScauaIcv\nrLzxn653PGDTGdG0F2zWIYDKUHypoONMO+2+a7vOmBarfno7ocxoRTPEZTOucewxS3vbybHlt6F9\n2jc4s7/JvLiU/jv6aCW3rWQbGUOUXTnWGz7t26t9fOUz22xXU+uJf68gyq92wJAsfEvxRQDAvngz\nte/jYGjXbGh8/riSBFb8+XiW7NmiOBPz2xmgn632wCxkPZtyFXpkquso6FPJDY0T19njvZY/QO4N\nr/f+M8g+tRK+vejcDMMYPXa9GsZsYdesYYyHsWRau6a8kNvn5w5+bQwzMQYj/3OcFXp1thiuU8VH\nhzjWaHBlVshY2RUpNeKytMmKnAR2sqLrWBVtNqm+vkX1jTWKjTxVWwIA3FOlF86XalcBAJarFPO7\nyor8aoWUtsNleste4ky1N62uV1yra9vO+lJE2wplGgupyaIZljkGsuw4TpTvVcqOs8qxVNHk8bc8\nbbfh21ymvWiLouNhe/Ww7SjZtVR7ooQHPG8bSjFvtNPr1dtaEedzoB0ny5oSo9uOU/XOvumMeWm1\nu2i/KKBia3VdZ7uLQTHq8zEpvovxFvYaPuKnLUrJ1e4OhTOs9at69qAgT6uDxNjjWIe0Xl/zHnOG\ntVEyGe8VwzAMwzAMwxgTY1F4X/OCv9/3un905/8c4kz6497GZONA76pfWjZuN1SfGPk2isSVj4pf\nmNiWe4BjeH2JFLl4i99mP0O/kUsb1F47x8qdZFjjOKpWLU6XVVILm3MUa7lOBc7XSFbyVY4R5gxs\nc4t1AMCBRVJ6L188BwB49gLF/F5To3PkmsppAMC15XpmF1pKmtCeCXmOARuigLbTiqnEBCcxv0j7\n7baVjtBSamZLSRntzPLh6BDZGOLuMceins+DjqGOEQ7FBGeWd4ldDscNe7W8WHywIDG24uogcdud\nWN5yqtyQ9na6fZNjgjX6M5kF8twZBNfu3i85xDntyfb0BALKbV8K8ZBUxaEpsdMWI9tnnPW07cYw\nCJ3n3Zi9q9owDMMwDMMwemAsCu/Xf/S5yf/f/sYP9rTudPioDjaHu7eOD2kes8l1tcd3XT4ORdfo\nkTJ/NUT85v4+UsjWriRFbOMy9kldJs2gtUTKbLzMb70vUAzkNaukyN6wTOfA351/sKdp5KmlDzdX\nueT+O5aLUqrfuM9XYNNesNrrVbaRqQccCDoxwux44dKuCJ3tptfLyzbW6bd71jEh8t1dIGS7cRL7\ni9T6rWS89P5GyfoyD17O49A802m/tDquHTO0+4J21pBjsBLTUzdxVTjXonRLZ1uLAIDNFp2v5aiJ\nXriifBYA8Pn1q3tabypQfrpJfL1eHlDEMu1DiqkMqqy7yY3TLkUWnd+o4lInuf28bffrwhBYL3T+\nyPnarsqjiJzxMaYb3me9577k/+97z03j2ORM8MOf+QsAwBsWL0x4JpNm77wMt1eQUAZwWb5AN7L7\nv0Y3EPvuo7+qYm3UKekrxTXpMz3XphuRT7krAQB/Xn4ZgE6q4nZFrJFcqp3vczr9xDqJv7E6dVkP\nyXrJ/6P0Op0xfaoeakdSlzvAdOlKfKMpJSfPKHE9jvmlt5huCUtcr3C9WqJjWY355Tr2equVOClH\nnC4rfPMmVlrygpXUJfFEpx+FKEhCiQWui+XbfJJwgi26+C/LAr+MNx/RTWaLQz/aKkRCXtIr8U1s\n7OTGn/o10ULD09gSXqJf3JOb5U3+63W2RS/UPdla4jrfwDbpBvbJBtUf9qs8B/kR4VP1WP2oCKVd\nlv5XVeiH2X976kUAgIPVcLamaSUJQRDrwAJJpVL0nOyg4Ao53XZ9Ma3oo/qicx91QodR91eM5KW+\nPu3BktW9atel7ld0HKny93OrKi9Kqxeod8FCGgzDMAzDMIw9zVgUXlEyje5MR9jG+Pno2RdMegoT\n4v5JTyAXX2F1b4UUt+1lfsS8xFZUS/y4f5FfVmORvrHIJuALrI4usn3YQjrU4eA8PYpeqrBFGKub\nHbVTbMfSaXOr3F6N0rZktWR5I5tCV6XOTVLoqhCDovT6QpMOVcjt3+P4OkQjhIQNPM3hAU+2olR7\nyJ5M25tp+zGZb8a+zMdo8gt/kghCwj1KKsxDUkvrF+209VmT67J+JKo7K8dtJ+EZSM1Nf8YSuiAJ\nJ/7bmRfTvsujgxlEK2ZJwgl50uG625J1lqfbgy+dDVt17caEQwH6ftltxKEYoc84l2H3K0Du3HKW\nJ08suC6XpuSUiZrqiVwBTOE1DMMwDMMw9jRjUXjf/dC3DTzGW098cggzMaaJ167eOekpDJ0iL+B9\nYAzzGJT2PP2M3t5H5cUD/FLRKqeb3U/9tveT0ub2c1wo24ntq7DVVZnKxQq1L5dJ0V0oSdwpqbAl\nUXh3UW5T7a7RtV/ZNZNlonxuK8uqNcwVOgZ56WW1VVavaDWzX3pVqLPzSMe/SglsF1t/wO0DnRfg\nekWnTdbjhSzU5Jz48Bl6p+SB8wcBdFJfzzKJYqsSTXil6AZVVP2uW06sZYiJ5oyY9pfeppUhfmjD\ncvbTH6V+D1W2U+Tr2BRewzAMwzAMY08zFoV37o2bA4/xPgzm7iBxxJe6RdilygObh8aynY+iSFzy\nrSOfx6BEW6SSxltkQ1Y9z7GWW/QbeY5eakezym/mV0k1bXO5yX7+G/yT+kn5aS1qk8RjxcoxQS1H\npB0VlHNClO6HyHdUCm5zmZKXq/SysjziUlwWYo4vrZRaXLIKze0SdyxuDDV2VajF6XhjcVsQtVrq\n4rIgKrW2LQvZnwkSFxuyRUvaWeLTiS2kPX95aHy1fIcy3plbuk9mbLjMut3mllkfenn39b3ajl6u\nGZb6PklcW4J4+W32ZEH3/nmxuqNyLJjW9MHG7owsvbJCnx+ZOGZxPjSF1zAMwzAMw7jUGYvCe+QP\ntsaxmV3p1xFgluNMTc3ucPX8UyMZd1zK8bhxTU75y96GW/tIYr14hOoXD7MKeZhic+cWqBSv2Wos\naijHhYoamqijaTVUvGlF9Vwq0XeGxJMmsb0S6+ukzk4MTtTUBirizpCJ8yUlVeI4tXtCVjntnqCi\naGrgogkvQoqqbKaTCKNYiuLc+SmlVsfudmJ40+S5TezmXjHIukC+c4XsS+IQ0U47RmiXh3qL6hdb\nFKP+6Pq+XcefBdqJFzbVi6b0HbnCOo1uDaPiEoodHpsyr314ebsSy5vYQRe4mzWF1zAMwzAMw9jT\njEXhvfXKT41jM3uWfn1681L6XooMPY3xSu+rzIJLA1qkyDr2Ooxa/DO7zfGALf5Z/QwF6168QEqZ\nL+2IpQXgKjTO/DL77y5SStgjc2sAgKsXSHm/pnaK6uUnAQAnSuSPuhTt/hXVUj//2zsCuTLL9Loq\n6Evrmtn+OctVvGqnn+vaL1nud1+eryinY2+10qtTI3cU3rSLhVBRThhSLkX0Gc679GvSjSQlMZVb\niV9vKUkJvK1SBHdSB6dTCncUWZVauK2Xs2Lb1gou+/6ygiu+utJP6lctkg+vxF8/itlXePNSB/c7\n3qB+vBmGoIKOPH501pXaQbLb9bqpYXn85i1X56PE7iZlgSBeU3gNwzAMwzCMPc1YFN5LNZNYr0wq\n5vZ9X/zmiWw3j4+98l2TnsIlj7zpXd6kcuEUOxassVrILg0d1wWk6iJGtmPywD0dkyR+Kj4GAPhC\nfF3X/q05jiGeI7Uxnue43BqrjXOkNu6vkRK8WiUnmCPVC9hfpv/vL5GavC/mrG7Rxa77qJVOUR2F\nxGEgic3dPfZWt/eKzlgmaudmq8J1jj9tc13Fo24l6mYptbzRkvhVVj25dCzRiMuExFMnWe+U+4Rk\nxVsoUdz2YsxlUqfPZinawlLyfzr2h2NS9pfK0k5jPtUid49TzX1c0nnyZIP+dpxtUCq/M3UqJYPb\ndqL0ssrMJ2ArqUep+nP2kb3IapnOjUYvaZqmHFHtSlusdCllVnx5M/So9uXFBoeU4EIK8YTiQic1\nzsScDjL/6baw+7qhsZN90WWAovse2r78bXJtOcHyxzKF1zAMwzAMw9jTjEXhnSW3gEHiXvt1gpg0\nN19/z6SnACDrpHDb+Rdm+uwNV4Tp9+EVRMFtlTnD2grHaR6g5c15djxYYEV2nv1650gdnJ8n1W+F\nFdmDc+sAgKMcw3ukQpmtVkrdvbr78aIV1U7UwSe29/G6Ota1eyytXh7yfo10di+V1StSEob2dtXL\ni/YXJwsp2yUd8xtwfQjU8/t3339hvUXqvSjOT2GJ5ttFcun1GAlz7LBxnM+rkDewKLza31dU+iNV\nOu9WWf2X2GBRt/cCcYOOaXJeJB+XeFizm0MoRrdXF4dhqrIhlW7WY2oDTNyDuNtx1T63o9r0gAPL\nE4tODG/+OqbwGoZhGIZhGHuasSi8l4pbwKQ9e9+wOPt54PP52qQnMDAz4dLARM10PKAuW/Ps5rCf\nFLj9K6Scrc5TzOahGim6h2ukrF1WfYbaS1SPWNGL+ee5KHziBRvzz3fpJ3G0G+1qqr8ohzF8Zp14\nx7Ju7cm2oPqp9Trtqq4kkTggNcQ5MlVIfYhzlJDgeruvhth1H3gaVRDRfcVZ4zTHKz/ZWgQArLUp\nBljcHuT80G4PUh4sXUitJ/HKe4GIFd5WhZVcyV7o0spu0p5kHlSlUPTteb1aKLaz4PqpsUIn5ZRk\ncxtXLO5U0+MxyByzHtfnVxpQqsuK+R/yNH63GYZhGIZhGMbQGIvCaxC9esB2i2HdjbfPUKz0sPjQ\nvS+a9BT64OSkJ1AYx+azHZVIFqRLx767klnt2Px5AMA3Lj0KAHh2lfx1RV0VJU57vS5Eda6nFbe8\nrGI741BDWbtC2b4kjlOjM6PljRPKBhYcp8d5hverN91CVM7txC+3uyuEbtfZy6RsJu1Rpi7/bycx\n2N3jiUMxuXn9vYrVlfZXHqb3El62cB/vK89J6d4xn9/7KvREopmT0W2aEcVMYhozmdfUrhX26x3Q\n01UlDixEUUXWdQ/5zvbrYdt7ml5U1EEV2x5JPnN9CQbGTcx06rv328nsXt2GYRiGYRiGUQBTeMfI\nXfVjXdvf/dC3jXkm4+GtJz458m388t/5/V2XDz2z2hC4btIT6AHXJAmlWdXxgNIhVSTxq1scY/m3\nF8lVY5Pf4D9WPsf9aNxNUKxlpN7O1zG9gsTVSjYwvd40EpqjdiwQuuvN6FumEoX5QqsGoBPfKp/J\nOreL0p3nXqHbBXGNKJfIkaPsWiizZ6/ESUsZqfhpXVZY4e+0syewqpfR6t4u4yQx3nQ+iQqt46lF\n4RWf35mEd0krueKNHTx/8mIpc867UainRZXbiTHtMbvD+FB69WcelXwacA3pJy7bFF7DMAzDMAxj\nT2M+vFPAK4/054Mr7hfTqhBP67wmz29OegKFkRje+ip7HrJdqY9ETqKiuUlfJadA3rfnL5Jq+Ngc\nZcw6NEdeuMfnqTxUWUttp5tnK9BRgkP99HIgq5xqNS9vebjf7h6yoX6C9vfNKqbdPYc76wfaVdzr\nbh7FO7cfmlfecj1fGV8yvV1EOVmu/XA7cw54HAdicjPLczySZbl8Rgeq5B5ymH14j1XoScPxMrmG\nLLEqLQpvNZo91wbJPNXxJ+VMVIkktvv6Y/XbzWPag26nZX6TUJpH5JWsv04zPtFKnpX+4j5S5KmA\nKbyGYRiGYRjGnmYsCu9Hfmu2lb7fPflvJj2FXXnvNR+a9BSmlmvK0xeTl+ePOk1EHMPb5m8K+YVc\n2mQFrclv4VdY7SuTurdZIoV3M+JsZzH9HP9riQGO5ZVynx6Y28X1AVxG0u6kzrGZsjxiz9y4ncT/\nlrhPHKXLMpfivTpXYqeIUjqD2UK8zXUqF2N6HXiey6WIVMF5dpZYjrnuuJ4s5/Hc7KmG3dAqifYJ\nTj7KVB/XtU+yXElmkeovyyNe83ybPpNzbalXuT4PAHhg+zAA4L8//ncBABVWbOWzBehJwzNN+n5Y\niSmGtySxxdHsZV5L3Bn4WhWlN2rojulq4qKQ46ebP4Fi3QqNN6RtTpVqvQuj8gkeqT9wn2OH5pQ0\na6VWzk++JJPzvKyWD1Phdc5FzrkvOed+n+v7nXMfd87d45z7mHNupehYhmGMFrteDWN2sOvVMEZP\nLwrvjwP4KsBBesDPAvgT7/07nHM/A+Bt3JZh/cTwf77c/U9/e+hjhpkOlfD29eX8TjuYRoeCcXNv\nYyNVn0bFd0T0fb2mYIVXfl2vn6D/+Ar/Hi/z8hKXsSiu7LLAvrxx3E6V5ZjfoufltZJSW1mJm+f6\nQolUU1FZRalbYlV1kcuFqJ4or0sRqXaitK5yn338M39/RCp02aU195aXrG6ey7Zanm5vST9ub3B9\nO+lHcAKsJBZXHAMaKnZX/G21x3BeJjghLyNcnGnn9fhruptCS/sl+w+1XxIjnI6/bcHtiFdOl519\nlPhg5aucxAdTKT66TzXpdD7TXAIAPLlN5Xqrim48Z/mpVF3meK4xx/tM54AowKL6i8vDGBn4ehVR\nul1KO6rkZULLMKT+05IFbfeNF+s26kxqcgiGdix6HWcE+xc8ZjntmfUCD8YkzD55+ljgAVohhdc5\ndzmA1wD4jzuaXwfg/fz/9wN4fZGxDMMYLXa9GsbsYNerYYyHogrvbwH4FwB2PlY54r0/DQDe+1PO\nucOhlV/y6rtyN3D1/FO5fXby9jPP66l/v4gTwiT56NkX9Lce+ltvXPT6me8d7h/1Bga6XnfiWuxv\nukE/u6tnSWnbOkI/pxf2k4p6zUHKpHaotk5lhcoaBxB21EXxRe2uTua37+6U0PIR1tqk2kn5+I5l\nqb45vrIhF4XO8t2zv4XcFJL+BV0V8ubXq2+uPmax8qoVoqAXcvqzTNqRbQ997iGSY1jQeUKUfnFV\n6NVxQra3zTKRKL1jVniHcr0mLg3l7vJexkM7M0DR6RZkStTTidBvfGu/25uSWOS+CLkzCEWz7rXy\nD3quwuuc+04Ap733X87Z9F48bQ1jprDr1TBmB7teDWN8FFF4Xw7gu51zrwEwB2DJOfefAZxyzh3x\n3p92zh0F8GRogD/8zb9N/j///Ksw/w3PyvT5C5zode4zx1df9sG+1nvD4qeGPJPeeNPD39LXentJ\nwX1g81Df65664wmc+tKpIc5mVwa+Xk+ePIn7n6JzbnXpKqwunMDcGXFrIIXXNeiro/kUhRzeVaWy\nVWOVqcoxvXOkmNUW6K36lQVShBMnhYyDQivVLm/NlwLtouyVkoxe7R3/b6X6ZLJ6BdprjuOH2W2h\nopYnaqXE1CpVWtorKqtYXgxuKPa2nBm/N7SLgsQSb3FcrMQQb0NiiqWdPuMNTxnZnm4uAgDOcBzt\n2WY6Hl40UVmfts2Kbo+3a1rRzUOOWSSz6FHxqrPC2/AxHv3iaTz05Yeo/dDJ3gbqnYGvV4Cu2Ufu\n+iwAYOGKq7F89Dkdn1Luk7zlHnBpCNJrxq1+FORB3RamnMIq9rB+1szSz6N+P9sd+7j2+P24+BA9\nOT15ci2wAuC8L35knHOvAPBT3vvvds69A8DT3vtf56D6/d77TFC9c85fe/vJwtvYy/R7wztp7IZ3\nsBtezQduuhXej/4rvN/r1XuPV1/3NmqI2fbp+fsBABtH6WZmm1+taVfp+0PeGdpLN7zZdLZ2wwuE\nb3i7b7u/HLG93vAOys4bXgC4snoWAPDT138MzrmpvV55Pe+9x8vfQPaZjQV5aY3LnEfEdsM7euyG\ndxeGcMMLANU1avjcf/2p4DU7iA/vrwG4zTn3QwAeAnBLqONNlz80wGZGw9uO/fHYt3mv9kMcEred\nf+FoBmYmfeM6DXHUw5zDB4Y2Uk8Uvl5TtPjmbY0dCaryx5RvjlgualXTN7rxErsoLNIN7uFFiuk9\nMn8BQOcmTm5O9U2p3NhKDLC+Ka0G2iuuueOGVZbR2PrGNGkP1OWGtJK4MezuNJC9UeQ630yJ00AS\nNyp17B7rO6xY47wYZCF0Qx4lPzLo+F5eOZtaLxQbDHSL91VZ7HZZd+e29RyLji/HeIvNO+XYb/HN\nfJ3b5TOcgEuDpufrNWqyV3U7eeefCpF0dcK1wI2wznA1FnJu0JLTY9A5jfvGs1cm5dIwCoY1h7zP\nIvHpzf/Qerrh9d7/OYA/5/+fBfDtvaxvGMb4sOvVMGYHu14NY7SMJdPaJNTUS4lbVu4Y6nhvvveN\nXduvWjrbtX3UDDOcYDr40qQnUBx2aVi7jL4q6gfo5/TWKv2abh4gVXR+dRMAcNU+UnDFz1T8dGtc\nr7KiK7668xGFOsxzNrOkztnLlnb46wLZuFphZ9iAViQFrQomuxhQQEXt20I51a7dGJJx1PrJ9lg5\nTlRHXq2GqOt6YUVW+itXBj2OS/dPFOFMe3dXiUTBZtUz5JiQqSt3iLZ3Xdt2bqszhmrXnr6++zER\nMp81S4LiuvCceQqBvb72GABgwdF51lF6aV8fb+zvOv4sIApXJ+Na2o8316UhGajXDffYf5IUnWuo\n3yyFCuxkEvPucZs67CP4pEGPy8vlCcdujDdQyjAMwzAMwzDGzFgUXmO2eO81HxrKOKOOLTZGj+MY\n3uY8/YzePEZ1v0oK2eoqxeYuVakeqRevpJSX0aTU3q9REkerXhCTfpkE64SO1625VhIfLGQV0XQs\nbjlpb3dtl3pHse06lcKElOZe0TGzIToZ3fiFQ8Spuii0DaTrWjnOKsFpxTnbP+qi8O6uKo+a++pH\nAQCrMZ23z+NslDU+f8615gF04rBniYzCy2YZeRnXOgMU205IIc6cjgElrl+f1a5jDpncS2qW1OwZ\no/CLiaHzr0DYvSm8hmEYhmEYxp5mLD9jX/+FNweX/Y8Xv3ccU5gpfvWJV096ClPBg2urk57CiPjo\npCdQnCb9bG6L3HmQYmgP7N8AAFRKFCPpWBpxSrEtBdTWrLMBlZvtSro/0o4GCxzjW+NSU3ZtRLwN\n/eZ/I9nm7oqnqHvaRSHPZWGb1xNVU8bRrg5t333fW6q9M066ruNY2wHJI6Ns52Ru0+PkrV9knFAW\nuFA9b1uZfj1KbrK9Y3MUa765RH56L5kjr3g5vzb6c1ObKB2XBrYKrPF1QJdsvjgaUGQ1GRW0Rxuy\nXCV4FFyKdl8TZtgZ9HRMr9h9y58YOe93wxRewzAMwzAMY08zFoX34oVacNmrPvHjQ9nGx175rqGM\nMw2M29ViWhXlSblCjJr/NekJ9EKbM6yljQpwfm0OAFAqc8xtif1xy6T4LlVJVrrnycOp9SL21xVr\nUKmLGit19sxPElLEup8kZ1CJKJzzwaQV8yVS75bZIWK5RB7BK1wusiPEvniTS1KxD0QU77mPnSIk\nRriRiUcN+fR2V7V1rKxWjHXsbKIYq5hZrSzreFk9D/EFbqt5NtppX+FmO1Lj9e6wkOe+0BkzXQq6\nX71Fc7/YYD/dFs25Lpn/WrSdxHpWPXlYqtFnKO4hTzT2AQAeLpM7g7iB7MwWNytohUtcGuI6XysN\n1U9C0tvpslTnOH2dki3g09upu5zlobrL75szB71cKOwpPOzY3D7VzaElqBj19keB2raei/ZiFrvp\nJHa3wGdoCq9hGIZhGIaxpxmLwnvz9ffk9nnt6p0DbeOu+rGB1r+UGfTYG70xoUxrfeGbpNiyKAh/\nlmIeG2VWOSvs4rBA8lEcpd0XXsxZFi9ssyIctVLLtQor6ql2dygp9wbtArEzM1fSlqQATteTfkpS\nkPhhybp1urHC43XPOCZox4kkhXAg+1fcZc7dxtUk/Z2opd3b4VmVZz1Dxm2xapnMi1XXxCGDj3Uy\nLZFDpO7SDW2lgmr1ttGOM22iGkt7U8Uny3LJCrrNqrMouVus5Da43uB6qxmlynYzreWUa+wDzU8i\ntlr0GT+1vQQAeJwVXvHp3WhXMWuElFutkrLldSczlaim/Fhle5HPi2Z6vYz6mvj6unR7UVW1C0Xf\n1E/UvoAiqayndxmo2PZmjj73K3X8B1R7g2pxoD0vtluWd9xI+IkCn4ftcv5Om8JrGIZhGIZh7GnG\novB+6b/ekN8H1Gf1Ox8b9XRGxltPfHLSU0jx0bMvGMo4V88/NZRx9gK3/snNQxhl9jKtCaVNVuIW\n0/F6oqytb1C8vsRUnllfAADUKpxxjV0dFsokM5USRVeU3u7+vB1FV8XyihuE+Ps6v2Od7sproh4r\ntTikCOt6Z720kioxsOdbpGY/0yBPV4lflexytSjtHazLSG1Hk83AtrubQtHY3ZA7RFP16yyXWF/p\np9Tbdpy0JfHAOitbWy/n80otb7XTdSGOO7HbO8dFg8smr1fmeOcmx/xKLHArreYfLz+DmUUptuWN\ntEQmp8X2QkCCVdVW2jAlSGH/1MB2+u4zRORS0w9ZCmenGxXj3m4Pqu7Q4o2lW+h0zGRgoyXyREPq\nzaDgD/AAACAASURBVGq+fmsKr2EYhmEYhrGnGYvCe+e//O1xbMZQvGHxUyMZ9/b15ZGMOwu847WD\nZ6G75SeGMJFxwZnWrvq90wCAJ7+VXBc2LmfVb5tjNGtcr5JU0uK35dtVUnSPLK0BAE4skvNGlQME\nRcWUum4XNbQa6YxqpBBXVL+aa6Dsmsn/qZQx21xnRZWlA7YrRY1jVMtcVl2Z6+KqkJZ/2kp6SDK1\n+UC77q/6yXIdyavHE9032y9dl+VaAW6puFqoftopoeMy0V1JzoyvXCJSY2Q8hANqNDtPPLJ9AADw\ncJ08uZ/YIiX2QoOeJFyoU7mxTXKkKL3i0ixPHip8HlY4hldUe1F6JX77VJNcG8ShY5aJGnw+sVtD\n4rQSckCQxT6wfJxq45jdAmYtsd7I3BR6+IyDUxiWg4SK005MGqTOJ6jUm7X8yZvCaxiGYRiGYexp\nxvK75tu+8rpxbGaovPJIvrOEMb1cV3t80lPYE4hLgyvz2/D8Kzq64TwA4Ipl8qidK7GaymafoVjc\njSa9/b6BKi/vHpMbitkVdovT1Q4OQsZNISdmN1lPxRmH3Rp2d3HQyqf2641zpI98F4dB1999uT6e\nva6f6pszF2EpJo/kG+YfSZWdcbp/xkLoMwo5aAibs+jSIMoXuy34OK146UMe0sMKOxxMEzM12RGg\n93+YCnC/Y4U+k4KfVegJRLC9gHxrCq9hGIZhGIaxpxmLwnvqM5eNYzO78pJX39VT/wc2D41oJnuH\ncWeE68Zt51/Ytf3ureNjnkkvzJ5LQ3OFYiW3KKQS9ScWAQAPrZMSFpfTb8uL3JTNeKXru7cL8qM+\nyqwnqmpnfd0nqasxQv20Kh1cnlGl+3Oa0E4VZVUPukqwKin+uXluEmWO/tVKtPTT/sG6XeqdWN90\nJjZhZyY4HbPbUo4W3eJ9u28jED+ssr5l1PokblviuDm+W8WEyz5Klr1zM5hpzbvupRDy5dXojFYz\nQY8q5J5zXdD7H5Tv+xh72s4D3ged/bNVsRhewzAMwzAM4xJnLArvR970G+PYjGEYw4KV3WiZMlFt\nLdHP6XaJ1cE6v3U/z2/BL5LHbIl9UeVt+Ar77lZidmOI03WJ+ZVyTpXi2jAf0Xv3WpnrFlcbUiwl\nTrMSWLejbDbTY+Yon1oxrWQyr6WVXh132lJyU8g9QRNyUwjVtYoaXk85KeT4/grirLDTkUG3JfUd\nKjAAbHN7sk/y2rzKCifxzlo51ueDZkvNQ0J25bwTZXdfROUprHQdZ6qRmN2Au0JeBrSg6pknnE2b\nAmiE6eWzGrNTRi4qw1+SUVAU3wJh96bwGoZhGIZhGHuasSi8v/rEq8exmZln1DGx9jkYRXHsv+tX\nSOFtLLGTAPvuNhc4vjWiUhTdZ+1/GgBw/fIpAMDlFfLdnY9IAV5gpXaB68KFNsUIr3GWMnlLfq1F\n7estqj/TnM+du6jBizFtI89lIVtPx3MeLZ1PLRfFswHJUBZSMZUqie4qZWh5O6BqtncoqDvrQsbr\nVrKWZZRbrQAX7RfabnH5SKvcIbRjRrCfUnblCcFSvAWgc05IuRyR+4N8xktcX+Ll27NmzAqgHac/\nt5Cfbkbp7VWh1R/JkDNuDcSo1OYpzng2kvWnCTn2oui2VbNk+1Qxvd0whdcwDMMwDMPY04zlZ+zV\n80+NYzMzT8hxQLhl5Y6Bxh+Wgpw3z0kyC/67H5j0BIrQ5DfyD1FWve1F+m0sL6+X19nr8yJlqNp4\ngsq73H4qo+fQclaAZb0kN32Vf6ZXWFXlDG2lMmdcq3DsbpUVuQqptYfmyPf3srlzADoxvTvRqqB2\nI9BlKNZXlM5TzXQ8Zyj2N0I6BrjmuscAa79crSyHFGjt2xv29c3G0nZrl/W2RVFG2vkgpDgLepzd\n2mVMOQbVHZnxgM7nKE8CpF3697oPOiZYxl+KtrgkRVeeNOzjcoUdL7SqPQt4zqgmCljU5ExrHNsr\nTihJqj5Zr8fY3VAscO44Wl5TmbR6mUPfDGm8YZ8emQceRccPHbtB1+9nrH6PSVE1Omd8Tpa4K6bw\nGoZhGIZhGHuasSi8s+hp++Da6qSnkOETp68daP33XvOhocxjUKV5lMxGnPIM+PC2SSZqLtHP5voK\n/bzeXuHYXvmpnCi4/DNd2p2qcz8Xp2N/pZT+7RatsFWngKxGk5S7tYsUy/vEGsUUf8UdpWHZ87bM\n7hBx1E7iQ+Mo7YsraqF2iFgpk+o3F5Oa3ImdTSuozcT71XVtF1Ww2U7rCDV2ptAOFLK9+TgdX9op\nJe653rW+4Khfmft3lGH27U2UZZ+ed6IEd8/4to20optVT7vXtQNDw5cyKrFWi8+3KSb7vFIddRyy\nIErtIsfmSizu4dIagI5yK4rtPKv4EuHbUvsunsfzfIz2RaIgz54W1BaFtyXXFktiylK4bzcGjVLm\nCoZl97a9wJihfeh5DqHN5hyj4HbG/WBg0O0NM0Nbn59/5lJXMbtFaZfzV5i9q9owDMMwDMMwemD2\nXkUdE1ctnZ30FIZOnvq5F2Kt+92Hnzv4tSHPJMwsxPD6OXJF2F6mr4iNy1mBXSG1MlFmuYxU6STb\nWGC5qK+dUtweOP6VS/HtFTV2vtRdJRW/3sj5JBY28cFNYmxz6gEPVx1zKwyvf/d2URkvtOdSZah/\nrMaPVD/tjKDH0fPT+xEav8bt2nlj5/rZuXTfVnYOu89Jex+LYltL4rTBdcd1jiVOZKS0/LkY0ZOE\nxixmWpNYXT5EknlKK2iF408L9hv2eMU2GmgetcKaJyIOqjDPXuj4wHPWannhkF7lQhJ4KJTCFF7D\nMAzDMAxjT2MuDUbCLMZaD4s3PTzOfb9/jNvqj/YSxVZuHKHfxElI7nn6yvCccc1z3JQvcWxvmdVS\n9kR0op5GkoGNldtydyV3vsTxq6zkLpRINRRFV7x1xV+1m2oazCgWaE/UvICqF1pP+9DmUdRTtl+0\najooGT9f5fqQtGcyvkVd24Ed8cUBx4wyK/Wh5RWnl3PmPqeCgBWH4gsAgONJRrWI58PKLyu9Z1ob\nPPfZ04Lk9BVlt11UpO4181qf4w2VWVRCgdErxEOk33joXs+bZDvyOodU+RJsl7v3y6xfYLuzd1Ub\nhmEYhmEYRg8UUnidcysA/iOAbwC98PpDAO4F8GEAJwA8COAW7/35buv/+Y++dBhznRp+5H23T3oK\nI2EWPGyHxUfPvmDSUxgZg16vANDYT7GMZRLEcOgOjuHlX9utMvvy8jdIu0RyksQRtqWd+8uv9TqX\nW1yeExVKfs0rt4eMf2/A1xe8no9852d8MlbaISKJOxbHCPHLFacHLkucPa4cS5l2eaiyOl2O0q4P\n4spQ1e4M7KYg9Y73bNqVQXvSStyqqJnazzfP5zdEa8QyWUgZ74ZkrdtiM01R3bc8nUCSge+Z9gLX\n6fy8yOmVJBPfiRq9e3H93GNUVk4DAMrJMQSPyzG/fAweb4lLQ9rzeFwM45oVv90W7ySL5V021r1Z\nK3PBI9DjoRkorrbPdYcWyzvscWZImfaZ/wxrQNWck/kvOY/zjt0QFd53Afgj7/11AF4A4GsAfhbA\nn3jvrwXwpwDeVnAswzBGi12vhjFb2DVrGCMmV+F1zi0D+Bbv/Q8CgPe+CeC8c+51AF7B3d4P4M9A\nF2iG93zw3cOYqzEiXv+FN096CsaQGMb1CgCldc5w9hD78c6xP2mNvWZr7EFbS78J3uJsNyy4Jdlv\nWjVWzqpcznO8aY2VtjlWQedouytzFKO7r0a+qoeqlGHtSJViMY9VSOg6Xn4GAHC0RJnXDsUXc/1m\n8zKWZTKP6QxmocxmyXa7Z/sKZS6Tcc42F1Pz7mQXi7uOI36/Oma2KfsV8AvO8xHOllFqXqF+Xh33\nnTG8uo9uFw7Pk5/usxaeBgA8d44U2htqjwDY4fmLtPev9gK+wArwF7auBABcVqLz5IoSnT+i9J5l\n3+e76scBAC+bo+002uMzMBrWNduqSqY1HeRIhZdUa3kxj3kZ1Nzu7XnjFWFaEt0Ny9c3l0G30+f6\nPe1fXl99XhQ9P3Q3CcfPc1/Q8ynwCkMRhfdZAM445251zn3JOffvnXPzAI54708DgPf+FIDDBcYy\nDGO02PVqGLOFXbOGMQaK/IwtAfgmAD/qvf+ic+63QL8y9f31FL1fGOau+rFJT2Hq+OW/8/tDHe/d\nD33bUMcbJ8PKRrcb1412+KFcr/VDpJBtHmQFLcm0Rsu3l1mpXeY41hV2U6ixUsvxr5UkzpV+fktc\nq8S/Rsp/Vd7i12WdFbdHt/YBAJ6o00S+jCtU/06mtdDY2qdXt0tMblHfXu0hKzG5C0kMbvf+goyn\nFV2tCHeU5e5KcWc9Vp75mOUpxuF6WtlttHW/7pno5DhV4yYqHIBXDZQSr1zlsuaaqk7H8snWEtfZ\nvYOP7b5oE7uhj/VTHAssPNg4SO3NZQAAh/L27MAxIEO5ZiXTmlZwk/h3pbwFlbh+GeIhG5uyOmpG\nHP868LC9fGbDUvBz+vuiD1fUeV7knCky9KMAHvHef5Hrt4MuxtPOuSPe+9POuaMAngwN8O53riX/\nv/GlFdz40mqBzRrG3uAvP1fHX35ue1ybG/h6PXnyJB665zMAgFrjuVg69pxRz9kwpobPf66OT/7Z\nPQCA9uGT49jkUK7Zx778OQDA0pGrsXzUrlnj0mHt8ftx9m8fAACcvHgh2M95n39b7Jz7cwD/xHt/\nr3PuFwDM86Kz3vtfd879DID93vtMfJFzzl9566/1sQuD8cMv+vTYt7lX+cTpayc9hbEzykx7H7jp\nVngdzDhEBr1evfd41Tf+awDAMzeQonrhWSITUdGaY4WXY3PbXPdzpI7GNfZHraR9d6WcK4sSLBnU\n6AfBUpmUuwXOoLZcohhe7b/bSGI20+VO+vXPDa4X+MhaKjJMx7aGl6cVVB1b21YxsaHlybg5MbZF\nY3HHSUjRT5YXfAKgPY53Kv4Auqj+6eXXzlOs8GuX7gIA/JdzLwYA/OINH4FzbqTXKzCca/bFP/DO\nVHvmNM5T1nqMuQwekSmJv00xIcV44kr1MLY/5s+z5yuN+6+doPK+//Mng9dsUfH4xwD8rnOuDOBv\nAbwJlJPxNufcDwF4CMAtPU7TMIzRYNerYcwWds0axogpdMPrvb8TwIu7LPr2IutH58b3xqtw65/c\nPJRxHvje3xnKON14+5nnDXW8W1buGGj9286/sGv7K4/cM9C4k+BSzho36PUKIHnjdd895I7QrFEM\n5bnrWNndz+aITX4zvKlUzG32UeX2Oqdei9jnNBaP23I61rci7Rzzm3jgclxtSTK2cQxop87euFET\npR3/31lKdi4dP9ppl7hRaU/3k3bJ6iV1ne1Nuy9kM5Z1X560q/V11q9W0s8F1ksrwNqFQo+rPWdD\nPr69etP2k62sF+/e1LZ4bo9s7QfQTdHl84k/O60Qt5SK3u2JwSgZxjUr1+r5axZ4UP6c1a4UVh1z\n+oXOhp5FxWHEkY5qvX7hgzAtbhNTTdETRh9LtV7UzD/YlmnNMAzDMAzD2NOMRXp907f/WW6fac3y\ndfv68tDHvHvr+NDHBMIK7axzKau1E4dj/Fe/Sm/D+5hCC1tVMthlu9PEf7ddZdVQfHjZd7ddJYWt\nXaHSs3+vWIOKUhuzqjpf5hjeCsXsHmYf3m9d+Vpqem2lagJZ5bPT3l0p1bGrkt1LyvOtBe6vPWS7\nK6Qh8hTPrBIcUogD7bkxw8ViirPboVJU05JSSbXrhVZRAeDedXLU2l+h80hisvVcBD2moOu636HK\nOs81rbprh43OHKkujhaNwDkxC7g77wUAVI5RFsntRXbNEA9kOdQ9+uj2HavbbwzwCOg5ljav/5hi\ncweNAQ5+xrudA5KQsqHWKbqNPEbk3xwVeC/cFF7DMAzDMAxjTzP+4NoAo1I9Z4FBY2/Hxas+8eOT\nnoIxIdpVCgScO0uK2OYh+q28uUrLW1eQEnvd5acAAC/c/zAAYJFdFXRcqI57zV9OdclGFlL6gG7q\nXtpft9s6ReYUGle3Z/ZFbSfUP7TPwXED42T76WPV3QmhMz+Oa2XpRrKVfWnjKgDA3eeOAgAev0BP\nvxz3X6qxk0aFytXqJg6yMv/8pScAAEfKlCFP3DaKxiELoXhkvW95x1KOSYWfKDy6vZraXkh5nmZ8\nnX2f67RvLh3K2+mnM1hNyId34g4GuzGgej0s+j5EAQdnyWK227EP+jWPmoJKcmjusSm8hmEYhmEY\nxqXOWBTeYTkmzCrveO3u2btmJfvbv/nm28a6vRuqT4x1e8B4PotZ8hbyMWfRWmC/2zlW1ioc10mi\nEprnKYj3bk/q371PUMxmFJOyJrG6ogZKKa4NSTtvN47aqfY4Sr9Vn7TrbGlRO5tBTXm4SrywfoM/\naU9iVbsrwHmerrGOO+0x45sgcaY601umXcWlxkm/ZtftSbvMM6ln4lyp/XCJEge9ZuVOAMB37fur\nVH/ZfgXpuNidSnKsjlVSD6jLQkcBTmd3S1wVAo4TISVYO2JstCnYfCUmv+dtbm+2Z08LKp2grIN1\nvojibb5W+DTmMOXkWMqhHljBG3D9oSqIwxqrX+eAaSEQJ5tk3RvrZIZD3hMBi+E1DMMwDMMwLnnG\novB+68u+Mo7NTC0fPfuCXZdfPf/UmGYyW+zduO4vTXoChWktkFNBY55+GzcohBZ1jt2tHyEVcPko\nqYDPP0QxvAucOa2a+OWK+phWTTPb6/E3eLfxtFLa6/K8OYbW17G5mfVydJXQ+qH1tEtDPeMCQaq7\njmfdy+TFOYsKvhSRorvMscRLrPCK/+4sxvDWn512s4kanP0wUnKfVvtmxdt2GplWqXSc85qQx7He\nrjzR2I3Zu6oNwzAMwzAMowfGovD+2VevzbR97JXvGsemp5JZidk1Ll1aSxTb2C6zlycnVitvUFk7\nQ2Vcp6+QCyV6JfypJZKAN1nhXSxTkO++Milo89y+UqL6Sky+rPtUKVnMQtnMMg4KyMbBdt6412/6\nF4v71P0zGdH0uH1mCbuUyVPFk37q88479vIZbbNi2/Dss8v1LU/qd6VNiq+cdxLT29TpyWaAc8+u\n7t5BuzXwLgZPWyWYJZdWQEibateFPPTcJ61eT3r7kyTvPArEJ/MrB7ti39CGYRiGYRjGnmYsCu/N\n19+TafvVJ149jk3vKV67euekp2BcIpTOkpRbP0DBuuuXkRx08TD9/G7OkzLX4tKVqP3hM/sBAIvz\nFBsp4YNOORFol4VyTEqbOCWIZ67UK0ksMDsquHS/nY4JYTeFYi4Jul27JISydWnXgmw9Pa54wHb8\nfPX20+N05pH2/y0j7doQUjv7VaR1xrrQ+qFMdLRMZ71L9xUFVvqJEitkPhN9DFxL9Usfu0pETxrk\n2GkFWPZlC2VePnsS2/qVNOcyWR+jvM7nH7+9rj1YfdqWujgFD81Uui8MyrTMYxxMWrEPHevQE4YC\nD4tM4TUMwzAMwzD2NFOTaW2WMeXV2Gu4OrssnCVlrLqPFbFlLldZad1H/Q7sI1lppUrK7v4axUSu\nVqgUhVYIOSGEHBDynBWKkKfcJv0Cim5nLrsrutl+6e0KiUIqSobn7bh01rE2ry8KapyooNR9K7TD\nQ0YruHnsjLvW2ebKaqgaGn3PC8jPipeZG8+n5tKK75ZnV5IZjOFtLPPTFi9x9+y32+ZjI5egupR6\nVmL3oso56D5NWg29lBjgszKF1zAMwzAMw9jTmMJbAFNwjUsOz9nGnqZY3tp+equ9MS8mnqSA1bdq\nAIDTda6v0lfKUoV0xyOVC1SWzwPoxFoKGfU0oPzqDFxJe1cf3t0dHULbDs1B1L+nm+RAsdau7Tq+\n3n4Sv+r1uN09X2MfOgbFjtWoSGKBfTrONpTVrO2jjCOG0FGvtQOGqidOG+m6lBfbdF7WW6XU+ksl\nOv+WuVwp0ZOGpUh8d9O6uJxHovDWZ1DhbS9wTPlT6XRa7RIrvRI/r9wWMu4LeWrlBFwahhoP3HUD\nQx5vL6rgIXo8dnnnSfJZB/x2pS6XaNRDLLopvIZhGIZhGMaeZiwK74Nrq+PYzK688kjWKaIoezfj\nV2984nTWT9nohxnItCZxf2dJmZ17jJQ01yK/3a2DpIStXvc0AODZ+55OrS7xr/dtHAYAPOAOAsg6\nJyQZ2Li9xAqwKMHiyiAKnLgylFW/aMfb+vqNfa2garVR2M1loNtyQWc4y7okFHNHyOvXDshcoaxg\nof5Fxwmvv/v8dzowtJVSq/vosRJ3jsRRQz5XjhlXGfsW4jr3p3at6M6zRYGOoxa/Xe32sNaaAwBs\nt2fv4aer0jFYeJzmnnwMOrOa8t8tKtDlKnP9Kr+7Le9TeZ24J/CYtj8K5bvXYxecQ6A90z+k5Mri\nSJWxS/Vvy7sW5sNrGIZhGIZhXOpM7c/YQRTZYXLLyh2TnsLYePO9b9x1+Sef/5ExzWR43L6+POkp\nZPhfk55AL3A8qfyq3jzEfqmc1Onps4up7uKnWxY/Xa5X+ee3uDVUuL3iqV4VZS8WxZb9eVm5q0X0\nFr8odtUonYlNli9E9UyWtjL73UqsbUcdFh9b9vpN3Bm6E+eoKS2ljOgI26wPrlKUAxnhkuV+9+Uh\nBTpPqc5TwPP8e+NdXCoSBVU5WiTrijqjMuWF4q63ksxpkjGtnColrvm+7aMAgHq7nN6uT29Xt6+1\nKD57q1nuuv1pxsW0E/vuoyyGjUW+Vmsccz3PMdZV+jxDNswjd20IxGQOZWxm0gJvkKmdWAf9ZGDk\n5CjBHYU3rezKctfDPE3hNQzDMAzDMPY0Y1F4r1o62/M6D2we2nX5uJwT7qofG8t2poG3nvjkrsvf\n9PC3jGkmw8ecNnqEA/Jcid9+r1JZ2eBYyovi0kDt+2ukKl25+AyAnbGYOtbW71oPZTHTMbvanUEU\nvwutGjZctWufvMxlQsi9IaQ6hp0lehwnxztWlFfJDtZAOktYJ1uZS9d9uq7dFaTe1u4Lqi4KtHjU\nal/hbv7F2ss45GF8RZn+RhwtnQMALLA6X+XPe4GfGKwmWeUcb2uLx0vLPDfVLqTaI97X+5s0zt82\nKKb8vvqR1HzW+dHF9gy6NPgm7WP54dMAgOgoZT3cOkyqddSkfZQY3laFld48hWzYSl8RlXNaXQ6G\npdD2Gu88amW4y/EuHJub81llxika26uI5BFayJWhwDljCq9hGIZhGIaxp5k5lwaJ7TXnhPFz9fxT\nk55C30zX+TIDLg3yynWZYhl9zOrROiu3GyQTuU0qHzhNitmDZ+haj+N2qpRY3kqJS4ntLXEML8f4\n1mJS9iqsEM9xXZZHShnsxHx26hnlMSfDWm7GNS4lHlSUT4kb1vHEsp2KkzmLE0B6rpp+/YNlfIlV\nlujThajefX0da1tQoS6qTHfbv5BXb8d/l8pz7XkAwNOqfVup0K3EE9il+rXU8rZSt7UvsDwxEH/e\nh+t0/s5ipjXPT13a58hZxe2n+HofkfOE+PFKKcjHJ5dN34rcMFXZaYt1LRjX2rdrgsSl9rjaWF0a\nCk5Or58ZL1AP7kpgPP7azbiO7IYpvIZhGIZhGMaeZiwK77Q4LlxqXFd7fNJTGDnTpdzuIdos+1TJ\nf7ddpt/GG0dJPyxv0M/shUeo3T9Oypz82hYb00aJ+tW5LsuTn/PtdLsvSZxh8jq9qnNZohXlzfQo\nKVuI+f+lUtrLt8x17SQh6vFciZ0gSuQEscDlXCzOENRvnusaURFFMZXYV60wC9oDVpQMrQjr/to1\nIWbdIhMzHFBkJASunad35Cg6IT/hIoQcJTQ6bjlPyQ0pyfJZrMQUa74vpgyCy6zs3lcnV4cnt5ao\nf2v2FN7yeQnOpU/Yx+l9kGtMkh0mSQ+LKrVu12pnOwPEBA+sWI4q9rdPdTN/hd7GD60+0+TthHwv\n8vkaNdKSsDzIas7lH42x3PD+3n/6e8n/v+eH/nQcm7ykCL3gl/fi3yzTb5jMe6/50JBn0ju/MOkJ\nFIFDGnwp5lIeh9LizaNU395H/Zr7ODRhH91ALMzRt9BSlW4Ol6uc6rVM5WqFbjgOlKlcLVG5xDck\nRW+mQkkXdhJKoNDLGDROsX4Nn77RaCR37b2N0+tNYXCcgtsLJb7ovNSWvnmUstmWevpms+mjJDSg\nKW3t9A1qMxmDb1DbUap/ciMry3W9nd63QwvrAIDL5umx/ok5SohyZeUMlfxynIQwbPGPlLNNSqhy\ntk4/3LaaU+vYGaT6NKcQXqB9aazwC3hLfCxVKEPIfqrXRAIjYU/cyQ2RUYV4DDDusJN7BENk+BKX\nS11etpTf9+VNicXJ34aFNBiGYRiGYRh7mrH8jP35t3xwHJu5ZBlV6MKowgV+7uDXRjJuMRaGOtr1\nn/3+PtY6OdQ5jAKfvLTGtmSsDvnQk17167zeoNCHJj8a3tim0IinYjr+j8b7aHiVmEJeWqtJmAHX\nF0qkGEviCQkrSOpRPSnlZbI8+7E88l7ainRIQqhf4KWu/H67J2FIXvxSj+31Y/1+5xHafig5ROcl\nwE57Yj+m5i5JPKKkH8HvoWCL5Z6tJMHE7gknttqVVD3pxy8anm3RC1xPNMiqSxJMPLh5AADw2MYK\nAODCFquis6jwnuXjfpCurYuH+FgssDUbR+IkH49OLezUck3opbYQ/ai0pux2p8fjMoqX2TLbGHD9\nwimn9Utr6mu8WXNd27thCq9hGIZhGIaxpxnLz9hf+u1+VLDh8Hs/8RsT2/asc0P1iZGMe28jv89O\nbjv/wpHMYxi88Zov9tT/fV/85hHNZMi0JYaX1cKyMqmXX93yq7pJC+pnyQKpHsmbBukXDBy/bBaV\nOi+ZAUCJ20vqxTKxMatyvVZKK8BSFyV4Lm5gLtpOtXVU4bRKLLZdUs67dF2SH8zzy2rTQjAlMduS\nday3uqcezqYs1lZhrI4GUg6HUg3rl+BacJn44UyfwJjafqzTP21DpsfpbJvqovg+sU2q55k6elNS\nNgAAHqJJREFUKb1P1+lJw7k6na/nL5Liu7ZB5SwKjdU1fkH0OKVTr++jY+CUUX8wpDtPcctRgDOq\nou5X5KDKOrP4AfTAOBTYFKPc3rDjiwvaojmlABc5poUUXufcTzjn/sY599fOud91zlWcc/udcx93\nzt3jnPuYc26lyFiGYYwWu14NY3aw69UwxoNLYvVCHZw7DuDTAJ7nvd92zn0YwB8BuB7A0977dzjn\nfgbAfu/9z3ZZ319566+NYOrj4Ydf9OlJT2HqGDQGN5Si+G3H/nigcWeF6658At6P5jf+MK5X7z1e\nffhHAADtqyi19sYVpIitH+c39ilkEtskJqGxzJZZy5wSeI6TIFQ4FrfKsbjs2jBX5iQNEvcZpa27\nShyQVYpau7bHqj1ybZR1H0g9naZYpzEOpTOWONQksYNav9dkBzp1ryi0ksBCz0fKitq+zEcSXlRU\nu6AV2FDSB6225iV5EKeDK8rkhHAFK+jy0vSGL2GNT5S1NimpF9qspLbmuL2WOiaS3EPH4IqLQ2c5\n25WxbUi9RaW4O2y30g8vdaISbREndVF8z14kt4Yv/oP/C865qb1eeQzvvcc3/2/0NHN7kc8zjt2N\nJf9IQcV1UJeGsauXo2TU+xL0dpvQdrttu9c0yAOuF3JrSJ5M6OX8lFFsy774n34yeM0WjeGNASw4\n50oA5gA8BuB1AN7Py98P4PUFxzIMY7TY9WoYs4Ndr4YxBnJjeL33jzvnfhPAwwA2AXzce/8nzrkj\n3vvT3OeUc+5waIzL/2D6Tbz/+a//l0lPYWS8YfHCpKeQ4tYrPxVY0ruDwu3ry4NNZiKMJjYaGM71\nCgCIxX+XlbVlKqvn6Of09jL9eK79/+2df4xcV3XHv3d+7eyux2ubOLYTJ4bEEAIhgZCEQPmRQqqk\nahRaqYoKlEKLUCuhlkJ/EKqiTtRKSG1DRQVSQWr5JagUSJu4KYWUH25BlBDHIT8cHIhDsB2v7SRr\nr9de7+78uP3jnvNm35m5897Mvpn3Znw+kvX23nffu2fevLve+c5531MjdfIEFaCgEsQ2xyWJ3elq\n9NGahmFOlINsFjlnmNq8P+gPb4PCE8X2nOBikfKCqazxRNEpnlzOmNVl6QwxVQjn/q4jaYzblbxT\nNKUzBHsHc+6vTxEuIawgl4KSwOHSxqVAYQb1g/pdR5EkjlzQztP48LaFm7dh3XmbNE+TC1mIb/mC\nfh5H+xuQ4xA6nlNFOe4K6qjQNW7mF2kMq8usFnfOM24VkoiZd+xxpmg5WLgbayVwe3DtI+TacHjF\nbSfzrvCEVIAHRWLrFUCDLjwb8NPt2v70uqfYAethbS89YrzEe3wMelaH11jKNykSV7XTVMnjKvm9\nnja+XW68iUVBijgnjvyD1xizAe7T5g4A8wC+aox5V4fTe6c7+MT9wc8zmy/FzOZLoyNTlDFh3wML\n2PfAwlDmSmK9VqtVPLXwIwDAzPyrsGnmJQOKVlGyx9GHZnHggX0AgOp3qwOdK4n1Crg1e+jxHwAA\nJi/ZicoFOwcQraJkk4XZp7AwewAAUK36Bb44Oby/CeAma+37qf1uANcDeCuAG6y1x4wxWwF811p7\neYfj7R2P3dLv68gEt808lHYIXXlseVvaIaTGn9/3zlTm/dtb+q/YdttL9w4yJ3DN69Vai1+9+I8B\nAKeu3Q4AqE2RC8MM5UjSIzS1GVIBSYltlkiJLQoltkTertTm3F4u9ztZIveFApXvLZKKWghvJ3Jc\nFpjUUvZ5XZWj2crFZb/YcP6mzN1t+cc2Q+eSObwtf9rw+Ti3ln15SyL3tkyKcBGN0H7OvW1zPfBk\nmvnUy6Dtefy+k3tCnOPicrLh8l3vOf4aAMChU6SWFmvB+7iuSGo4bWeKThWfKdA2z1unBG+gLavk\nMs9Yeg7L/GK+9qy6y9fKx7PiyznG7Obw+LzzIN/1pk8NOod3TeuVjrHWWlz3O3cCAKwRoXIOpKey\nGtNv7m5mywGvYY5+vYb91es6vyfedlwiPhYZG5ZVpbNBoP7L/b2EsFZVPmalP45VfmMh+x/8/Npy\neA8CuN4YUzbGGABvA/AEgF0A3ktj3gPg3hjnUhRlsOh6VZTRQderogyJODm8PzLGfA3Aw3CFcB4G\n8FkAFQB3GWN+D8AvANzmO8f3riz3HNjib7yu52PiIHN141QT8/nADqrC2bgxqIptAPC7N+4e2LmB\n7Kv7kiTWK4Cgwlr5eafQNbeWQrvpYXkUzoQlDfkkrSUf3uCzNu0n217Uqb3I8XPursjZDXJ386wc\nu23L15fU13wz8PLlHF728i0Vwrm8rRxev6cvgMDXd4L8eLtVeQPaXRSki8OinUAnfEqrVGQZqfi2\nxnv6I6QYqQRHxxXuv3mzSwNontc+T1zVerHprg27NzCssrOTRdm4a89V9SpBfy3UH7TpPZkjNfqZ\n2nkAWuo0n/+8oks94nth0CS2XoGWSgdecz4pV7RF7q7XTzciZzdS6etFCUzZ6SGq2pz3OO/4iG/S\n+01sHU6qeVei3qrI+0LcX95rwf+niEcU+FdIcTH6YsQqPGGtvQPAHaJ7DsCNcY5XFGV46HpVlNFB\n16uiDIehVFp76hPXJ37ON79hX1/H3Td3VWIxHFjc3NP4WzY9ktjcWUZWaPNVbPv47M3DCGdNfHxx\nEDF+bgDnTJbGkaMAgGKBPk5vDd/rxTNuW5+k7RQ9qV+mXN4pyt0tk9o5SU4IZafMsfrK/ru8ZTGg\nIPrZZ9ew767oX+3XG+XVy/m/BZHr2+7H27m/KCqv8RP/C02u7uXUcM71lTnDeYh2sL9zRbeiaLMS\nu8JtoZLyeaQvr3SP8LW5Olnbthlu18hKI2gLL92lZhHL7JPbZJ/csDwTpZ5PBAquy/Fdz04ZVBVv\nPXkBV2g852Mvs48vvTfPkWLMsXKOMHsJc+wvNFwltlLGquvFIcht9ChhrYHhZr/KbL95riNN3NfS\nY8W4tXof90wcZTimepyYoUmUskvbZsmE2rk6fdvXkAe2s7anFRRFURRFURQl4wxF4X3zG/bh0qnn\nhjFVphlkLmua9Jvneq5UVpN8Me0AYpBb5zyR7ZTLqSy/4BQv/jS/tJH9dt3H7LPbSTVd75S2oHIa\n5fDmSdHlilnss8oCMreD46ht+Ol79pw1YWWXcy1ZkZvINQK1cJLVQtpuLDhZeoNwAvBeAzS77pfk\n2wxPxX6PhOGbx3c+73nE+HzM+AOnA3EeVlHLtsaBRpyndznK91oY+Zpax7FXMPvsuuCmcuyY4c5b\nRtgLuQGn6LIqzpXf5kjZjXvNMgld/hr58Mqn1+Wl9CrAkn4rbbUd4Dl9PypmRlXjKCeMQRP7PfHl\naXcb4yFp/xL+worvz2bBhNqB/y59CcP3dVN+FdYBVXgVRVEURVGUsWYoCu8Dh3fgAewAANxz7WeG\nMaXSBZ/rRFbON0y+feyyFGa9M4U5e8MuOXWvvsEpYCszlItZofzRCilrThiDWSaVcIWqfU26j92T\nE5SDWaaqZaTIThTCVc7K0hmBq5/lwiqtzxlhmvqnc8utPnqSfyrIae1NvfNVBYuqBhZVBax1Xur3\n+ORyzqz0oJXzsJdslFctt2UcTNAfxNXZr7cp4m8dL1+vibVv9dxNcc3b9sv3IuY4Zue0+6bxisnD\nAIDNBWdSL5XkpUYMuShj8EsIqhWacL/0XO19gh77ebohqp1DKpAXPf+w4+hxvq7XKcqJImqutR4v\nT8cHRPhJ18vRN5oqvIqiKIqiKMpYMxSF950v2xP8PMpqYFKk7d+b9vxZ4vId8a6Fz2mirzkTO9Pg\n+ObC5wEAb3r73wEAVkjZrU+F/XbpIXoUT5PiVqcn9svuV8vJsnMsWJh0SnG57A5YR4rvzITLqcyR\nu8P6guvfWHD5tVN515a5noFzAClx843W/qi8z9Y423W/zKH159p2P097bq0Y74mX5wu27ObAA0jQ\nmOp4dLaRrzmoZud5D+Q1k1XvJOycweOkHy+fj3N/2a3hZMPlro+iwvvDr/wJAOC17/sEgHYlrU1p\n7TWn1uc8kLCiNxIk6TmcBL1WklvDVEMXrxN0A1GFV1EURVEURRlrhqLwpqkoJqnMnSv8+oO/n+r8\nr9v+i1Tn78R96M+/+YHDOzr0VtcUyzBpFkm5JcFrYp6UtSXXz4pvnUqnsRdinRIIGyTvNHIuf7RG\nbg21ovusfbrmFOCzpAw/l3dJwT8zzveXXRtK7J0bbLmfn8Jvee/yz1JZZUXXp/RGKb7B8W3Kb/f+\n4HyeuKR66cutDfbL3NmIXFvvcUI6kdXQ2vNs441fHW97DN1fW9ucMY9nZ45p+oaA/X7P0o3L26U6\nfzNQCLXZPYTfiVojroVB9iieda+iPiHcGuRAmRPJ3Z5+eZyPTPjzDlqGHEfVeq0k9X6Kaxsppvfw\nXqjCqyiKoiiKoow1Q1F4//T70WXA++Xv33hX1/2PLW8b2Nzjyl9fuavr/iz6CafjthDNlpmFtr4n\nU4ijXxpFLmfjNvOXuh+WNznZyE6QpFsi5ZfaubzblgqkvBao6lfQz1XL3P6JPPnoknvDVME5LLBb\nQ6XgcizPL7nreX7RPV1fNlxvrB2ZWxu8Jo8EJd0SzjXa82c7Xz9f3myn3Gmfz64vb/lM0/k+z9Wd\n0j/fcKX8jixvAAD85OQWmitcPc8IlV4qxVa4NvB+WbmPGWWFN1ejCnqU114vc/692x9UpOKH333O\nAnFzfHtUgjstv77zfH0x96k2JuYokbR6nUFFObZbg7zPosbL88fsn571/1/AnNu/4RVFURRFUZSx\nZygK7w2vGJymdd9cf7mV48Qtmx4Z6nxZdHmI67aQBf437QB6wDRJATvr2py7y5+yCzPkeTvlthum\n3MDNk6cBAFvLTok9vlwB0MqZZHx5tqzAnalTji/lYPJ5ctgWGl+k3N5KYaktF5fJB24H3XN24+bq\nRuXo+p0FbKjtnd/jWOBTYvPoniPsPz4cF/v6LpLaGjhikC8wt9nXd7kZ3r/cLARb/nmFtrVmntq0\nbRRCbd7PObXyveJvAmR/QVx7uV/eV3LL+zlX/OenNmFUya9Q3jzl8BaW6FuWpfA4rpIYVLTKh9uB\nKYMnp7LXHF8eP5DU3SCoNZ5m2ErqoPKY5evwqazc31y1P+iz7ftWtWFtx3O2fHKNaNP+nNx2HhcJ\njaNfGSgfmo88RBVeRVEURVEUZawZisJ76dRzw5jmnCUqpzYpRfZjj96ayHnSIFvOD3vTDiA2/Omd\n/XbzpBLl2KWBKqs1JsmVgZQ5Vuj4afkrKu4eLFIC4WLTKbeLDbcNlFra37YN3Bg67y+Z1v5iUFmN\nx9A+NDr3B0mNDlYuA2UzUDTpyX6hdK5Qv1Q8g0pnJGWU6SLmReyszPL5FhtCMbVhdbSloIYV1TrN\nsyxUU1ZXWc0MHAlEXqvsZ4xH9vIp6Z36pRruOycr9byNUnA59zaHsJIbHA8eR9eaXUPoNbKjxwS9\nN+z2cOTMTMf4RgETeFKH38cCuTcEzitOwA+UXbpNgkptwkCjvVJbXDW0ByU46apsXsU2K5XQYsYx\nMOWZVVeh6od2Rh2cMD3fA/zNwXz78zISVXgVRVEURVGUsWYoCu9XfnrNMKYZeQalQh5Y3JzIedYa\n30e3fSOROEadL6YdQA+wqnPmQvfZmFWiAiu8Z92vELte5ka68XMr7tHwI4tOMWPVkVXI5Tqpk6Qu\nrtTdflYA8zlS7Njdgbes2OXYf7c9r1Y+kR/02879UvFkgtxdz1zSG9inKrJK6VMfWfH1qd1TefcU\n8gwlVAeV1zyKscwF7jUHWOb+tq5H+HyyStrq8TJfuYSGaIdjLVK75HFxYNiruCZlSGKBvkE4Y2lL\n+cicl3y07u7H2ZUNoeP4veFc4VFmZZrW7LK7trZA6naJvbXpfqe0+kDlY8XMo+j2rDZ6xnd0a+jx\n1AMj6UDiOlt4yKBJw/DwOHHw/RPkpuejnVVU4VUURVEURVHGmqEovGnwzpftSTuEkeW2mYfSDkHJ\nCPykLsOfplu5vJQ3ukyKbdFtD8475YwVWlZHgy0/dU++u9OsFk6GVdSCkZXVSIGjXMuCaE/k6oHS\nOSHyfstBnmYt1M/5v1E+tO2V17pXTPMpo779ba4OHRTTjuM8bg/xx8vXKcdH7G973e16FCuxUpld\nIc2F85O5epvMf35R/gwAoELv3VyjDAB4tr4RAHCo5lwVWLFlN49jZyuhOGTFPtmeoO1kodb2GkYF\nztHlt4GfYmfFt1kIuzEwnMoe5cLQb47lQMmMNKxE4fNxbnNpiJC1i+5XAjY86RyBGls3Rs6tCq+i\nKIqiKIoy1gxF4X3Rl6f7PvZ7n/5MgpEo8ej//VoLr/jBb6cyb5J0qqzWzp0DjyMxRN7eyjr38TtP\nvryTs6QaveAqY52acPcOPwFuiza8pcproLahdp4rshUpH7XIlddIeSuEK7GxAscV2aZp28yvIFdw\nnsCs6G4sOCng/ILzBN6Ud4rA5twiAOBFeRfLOuOSGZtCIW2APVxtx36Gj2rQONYIa3ztSK1s+lRO\n213l5EpwZ6if24029bRA/SY0jt0kOHdZztOU52F3B2rzPK3x4fNwHja3m9YELh0NkdvNjhK+fpln\nXW/ya5b9nR0ngtianc/H3xhwbjir6JwjzvfVKMI5unx7sqIr/VTB5iQehc3rr+ojgYf6k3ZpiEtS\necmJjRcM2h84yevu9fr15IK3+f3KLbmO5GhLX8ghV6ec9Gn3e/vUxRORsanCqyiKoiiKoow1Q1F4\nb7rjf/o+9m+ef3mCkWSLbx+7LO0QUuFtWzpX3jtX8q5HqtIa5/XRp+3Fbe5TdX2aVM8K5UKud6rq\neTNOPb2ochIAcMnU8wCAjZRw1RRP1TeE6unrb4jjpLq4up9Vv+MrLn9zdsU9kf+4vVCM9c0dVh3l\nnP2Oj3KLaOUtkzcsOQVId4eCcGUIcpWF20PSBK4MPgeF6Iek+6atyp1wqJAqNdN234j76eBZl/v7\nLLmIbJt01ZrYu3gUCRReodi2vSSp7Ir+xImhUvatZPZ53NArqyVEWkp4HCJzdNswnccFbco5p28q\nau7LRJCFO5a28vHRv/dU4VUURVEURVHGmqF8jP3L8/YPY5qRQ69Lctx9en3aIYwlgUsDbRqTlItL\nap5ZofzQE+6p+Vlya1hYcvlUJyrOh/fidScAAJtLLsc58Ds17K4Qdk7oVkkNaDkRBO1VHrNcSU26\nHHiPZfUQ7H8b9tPNBx6x3AbtB8VmQu08uIpXjvpz1M5Tm/KgjVQj3bwnmi5BupIr0TUqdhzHNNty\niUUOso3YL4+PmavsO/9qnaV9bLgd5D17VPPWOLFftDkfeonylNl3l6vXyXxn5qqpg27cRjfuyaVt\nAIBjK6P7+4QVXhbic5xELhQ2Vs6kAsyuDi1fXqEYJ0UsxTdi0BorlXkPT0v5zbByGzDga9OW68s7\n6JdHfpmadJ8Xr3b/p1x5/mzkuVXhVRRFURRFUcaaoSi8P62dGcY0yjnMqyb0HhsEuRUnE7HSG6g+\nEyQfkcMByGWBK6QtLjqF7Zllp5wdPulyJMslp+ReuN45JmwoOacEVlVbVcdkW2yFQlxc5bkbpQ4X\nqV0S7SIanfv5PJ6qYK1KZawQ01PFtnOua/caYi0VdKFJUgaWQ/ujjk+LRpAf28pdbkjXBIS3zcCp\nwt1YnIvLyiw7TqzYfKjNKv1UbjnUz8ctUfkwbi83w/1XTB4CAEzT8WXj7svtpTkaP7o5vFw5jZUw\nmQvpUxFz9fCWsXQ/B5ckx/3h87fG9xrx4JExRebuJvwasnhN+ibqWkaJ8rnuxwWV/kS7bX7af3a/\n897+5cu+231iqMKrKIqiKIqijDmj+zFWSZzHlrelOv/HHr011fmHRzXtAGKz+/7bAQCv/sAnAACW\nFd0JypNlZZf683lSZsk/l9vsd1qi/lPLLud3peGUO/Y9XVd0slSe2uxAUKHSbutoW8nRlgyBVyt1\nvlzdKIVWIvNImcB1QaiXS4GUJsaL88j8U1+/T+3kNqueLTWzFDqOVc2aGNfaXwi12ZmAq56xJy63\nV7i/yZ651N8I+wUHfrzNHGqrfnZbeuKarglX4ivkWbkPV+TjSmh8/2wpu3y9beX50LXi1yK3/Jqu\nqjhF98bK4wDalWWOfWvxJF3LcN70KPHwP30YAHDte9yabeY7K7te1TFKjWR/VM9xUQ/jp0HiCmvM\n8w1a2fUq1Z7+SDV2VTtSBe81l7fPa8ZfTAS55kKmXXfY7fjCwdcDAN7fxfxKFV5FURRFURRlrBmK\nwvuWT9+C8ssvHcZUPbO0/0Bisb3vmu8ncp7V/PzB5/GSa89L/LxJkHRsSfrwvviJH+C610dXXkmD\ny9MOIILdu3fjhhtuCPVZVokoh7fACi8puHmxZUWuINqs4AUes7lwRiorcqcpj5BV1rMNp7jN5yZx\naM9x7LxuM4BWNTV2eWjanNfDt60tvHylL257vzyP6LcGsw/NYstrL+i4n8n5fGwJn+IcHO+RVnIR\nxx3dewQXvHZr5LyBny/lNE/nu1cd6/Z6fDHlO2QiH9pzHBddc37X4xhWpeU8L508DgC4qPSC2xZc\nTm6F7o/AzYFvZK5Gxo4Z1L6o+ELX+bNGxzWbC2+9xFTeIiuved6yhSNPoXLBzlR9eAORUIxbmH0K\nlW07+5x08Awqvr6UZ3HMwtHOsSVVkS/KH5odPCx9a7Swi76h/hX/qYei8C7tf3oY0/RFlmMDgGce\nzO4v3izH9qP/G93SoGmze/futEPoyqE9z6Udgpeje4+mHYKX2YeOpR1CVw7vOZ52CCNLltfs6dkD\naYfgZeFodmMDsh3fQobfVx9DUXg3PWxxyYm1Vf/5g3++O6Fowty19whue+OJgZy7X+6buyr4ea52\nGAcWN6cYjZ9BxfbRbd9Y8zk+lUAcnUgmzznaLzBrPPKPH0o7hIDq1iqqV1bTDqMj1a9XUb2umnYY\nHan+ZxXVa6pph+Gluq2K6muqaYcxNuz53IfTDgEAUK2eQrWajVgkWY4NyHZ8WY7Nh+bwKoqiKIqi\nKGONsVGVTNY6gRnVatWKMjiszaYzo65XRWknq+sV0DWrKJ3otGYH/gevoiiKoiiKoqSJpjQoiqIo\niqIoY43+wasoiqIoiqKMNQP9g9cYc7MxZr8x5qfGmI8Mcq6Y8Ww3xnzHGLPPGPOYMeaPqH+jMeZ+\nY8yTxphvGmNmUowxZ4zZa4zZlaXYjDEzxpivGmN+QtfvdVmJjeL7kDHmcWPMo8aYLxtjSlmKb1TI\n0prV9brm2DK7ZnW9JoOu155j1PXaX2xjsV4H9gevMSYH5w51E4BXAniHMeblg5ovJnUAH7bWvhLA\n6wF8gGK6HcC3rLWXAfgOgI+mGOMHATyxqp2V2D4J4OvW2ssBXAVgf1ZiM8ZcAOAPAVxtrb0Szm7v\nHVmJb1TI4JrV9bo2Mrlmdb0mg67XvtD12iNjtV6ttQP5B+B6AP+1qn07gI8Mar4+Y7wHwI1wN9YW\n6tsKYH9K8WwH8N8AbgCwi/pSjw3AegAHOvSnHhvNfQGAXwDYCLcYd2XpfR2Vf1lfs7pee4ots2tW\n12ti11HXa2/x6HrtL7axWa+DTGm4EMChVe3D1JcJjDEvBvBqAD+Ee9OOAYC19iiA81MK6x8A/BnC\nhRKzENtLADxvjPkcfR30WWPMVEZig7X2CIA7ARwE8CyAeWvtt7IS3wiR2TWr67VnMrtmdb0mhq7X\n3tD12gfjtF7PyYfWjDHrAHwNwAettafRXol76F5txphfA3DMWvtjdK82nYaPXAHA1QA+ba29GsAZ\nODUh9esGAMaYDQDeDmAH3KfRaWPMuzrEox58I4iu177I7JrV9Tre6HrtC12vQ2CQf/A+C+DiVe3t\n1JcqxpgC3GL8krX2Xuo+ZozZQvu3AkijqPsvAbjVGPM0gH8F8FZjzJcAHM1AbIcBHLLW7qH23XCL\nMwvXDXBfrzxtrZ2z1jYA/DuAN2QovlEhc2tW12vfZHnN6npNBl2v8dH12j9js14H+QfvgwB2GmN2\nGGNKAH4LLvcjbf4FwBPW2k+u6tsF4L3083sA3CsPGjTW2r+w1l5srb0E7lp9x1r7bgD/kYHYjgE4\nZIx5GXW9DcA+ZOC6EQcBXG+MKRtjDFx8TyA78Y0KWVyzul77iy/La1bXazLoeo2Jrtc1MT7rdZAJ\nwgBuBvAkgJ8BuD3thGW4T3kNAD8G8DCAvRTjJgDfoljvB7Ah5TjfglZSfSZig3tq9EG6dv8GYCYr\nsVF8fwXgJwAeBfAFAMUsxTcq/7K0ZnW9rjmuzK5ZXa+JXUddr73Hqeu199jGYr1qaWFFURRFURRl\nrDknH1pTFEVRFEVRzh30D15FURRFURRlrNE/eBVFURRFUZSxRv/gVRRFURRFUcYa/YNXURRFURRF\nGWv0D15FURRFURRlrNE/eBVFURRFUZSxRv/gVRRFURRFUcaa/wdUymdE6nQW+gAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb76e407190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# move all the data into one ndarray so it can be interpolated\n",
    "data_points = np.zeros([num_points,2])\n",
    "data_points[:,0] =lr\n",
    "data_points[:,1] = reg\n",
    "\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid_x, grid_y = np.mgrid[lr_range[0]:lr_range[1]:100j, reg_range[0]:reg_range[1]:100j]\n",
    "\n",
    "grid_z0 = griddata(data_points, training_score, (grid_x, grid_y), method='nearest')\n",
    "grid_z1 = griddata(data_points, training_score, (grid_x, grid_y), method='linear')\n",
    "grid_z2 = griddata(data_points, training_score, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "\n",
    "plt.subplot(131)\n",
    "#plt.imshow(func(grid_x, grid_y).T, extent=(0,1,0,1), origin='lower')\n",
    "#plt.plot(data_points[:,0], data_points[:,1], 'k.', ms=1)\n",
    "#plt.title('Original')\n",
    "\n",
    "#plt.subplot(132)\n",
    "plt.imshow(grid_z0.T,cmap = 'viridis')\n",
    "#plt.imshow(grid_z0.T, extent=(0,1,0,1), origin='lower')\n",
    "plt.title('Nearest')\n",
    "plt.subplot(132)\n",
    "plt.imshow(grid_z1.T,cmap = 'viridis')\n",
    "plt.title('Linear')\n",
    "plt.subplot(133)\n",
    "plt.imshow(grid_z2.T,cmap = 'viridis')\n",
    "plt.title('Cubic')\n",
    "\n",
    "plt.gcf().set_size_inches(12,12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a really good model on CIFAR-10\n",
    "\n",
    "from cs231n.classifiers.cnn_crp_a_soft import *\n",
    "from cs231n.layers import *\n",
    "from cs231n.layer_utils import *\n",
    "\n",
    "#data that is used to test if a model can overfit data. If it cannot overfit, ignore the model\n",
    "num_overfit = 20\n",
    "overfit_data = {\n",
    "  'X_train': data['X_train'][:num_overfit],\n",
    "  'y_train': data['y_train'][:num_overfit],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "num_points = 10\n",
    "\n",
    "lr_range = [-4,-2]\n",
    "reg_range = [-8,-2]\n",
    "ws_range = [.009, .05]\n",
    "num_filters_range = [10,64]\n",
    "hidden_dim_range = [50,500]\n",
    "\n",
    "solvers = []\n",
    "num_models_tried = 0 # number of times new parameters were created \n",
    "while len(solvers) < num_points:\n",
    "    num_models_tried +=1\n",
    "    print \"Found %d of %d models, on iteration %d\" %(len(solvers),num_points,num_models_tried)\n",
    "    # generate a new set of parameters given the ranges above\n",
    "    learning_rate = 10**np.random.uniform(lr_range[0], lr_range[1])\n",
    "    reg_val = 10**np.random.uniform(reg_range[0], reg_range[1])\n",
    "    weight_scale = 10**np.random.uniform(np.log10(ws_range[0]), np.log10(ws_range[1]))\n",
    "    num_filters = np.random.uniform(num_filters_range[0], num_filters_range[1],1)[0].astype(np.int)\n",
    "    hidden_dim = np.random.uniform(hidden_dim_range[0], hidden_dim_range[1],1)[0].astype(np.int)\n",
    "\n",
    "    #print \"learning_rate: %.3e \\nreg_val: %.3e \\nweight_scale = %.3e \\nnum_filters: %d \\nhidden_dim: %d\" %(learning_rate, reg_val, weight_scale, num_filters, hidden_dim)\n",
    "    \n",
    "    # create model and solver\n",
    "    mod = ThreeLayerConvNet(num_filters=num_filters, filter_size=3,\n",
    "                   hidden_dim=hidden_dim, num_classes=10, weight_scale=weight_scale, reg=reg_val,\n",
    "                   dtype=np.float32)\n",
    "    solver = Solver(mod, overfit_data,\n",
    "                num_epochs=4, batch_size=5,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': learning_rate,\n",
    "                },\n",
    "                verbose=False, print_every=10)\n",
    "    \n",
    "\n",
    "    solver.train()\n",
    "    print \"Last train accuracy: %.3f\" %(solver.train_acc_history[-1])\n",
    "    print \"\"\n",
    "    \n",
    "    # if the model can overfit, keep it\n",
    "    if solver.train_acc_history[-1]>=0.75:\n",
    "        # recreate the solver and model to remove the overfitted weights\n",
    "        mod = ThreeLayerConvNet(num_filters=num_filters, filter_size=3,\n",
    "                       hidden_dim=hidden_dim, num_classes=10, weight_scale=weight_scale, reg=reg_val,\n",
    "                       dtype=np.float32)\n",
    "        solver = Solver(mod, overfit_data,\n",
    "                    num_epochs=4, batch_size=5,\n",
    "                    update_rule='adam',\n",
    "                    optim_config={\n",
    "                      'learning_rate': learning_rate,\n",
    "                    },\n",
    "                    verbose=False, print_every=10)\n",
    "        \n",
    "        solvers.append(solver)\n",
    "        \n",
    "print \"%d models were created to get the required %d\" %(num_models_tried, num_points)\n",
    "solvers_backup = solvers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
